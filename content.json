{"meta":{"title":"JackYip","subtitle":"Blog","description":null,"author":"yezhejack","url":"http://yezhejack.github.io"},"pages":[{"title":"about","date":"2015-12-30T02:41:57.000Z","updated":"2016-06-13T12:59:50.000Z","comments":false,"path":"about/index.html","permalink":"http://yezhejack.github.io/about/index.html","excerpt":"","keywords":null,"text":"E-mail: yezhejack at gmail.comGitHub: https://github.com/yezhejack 理论queue 深度学习论文 支持向量机推导 刷Stanford NLP University of Washington Machine Learning 工程queue libevent［无限期搁置］ seletc epoll kqueue模型［无限期搁置］ unix网络编程［无限期搁置］ leetcode 已经完成的 spwan-fcgi 源码阅读 nginx flup spawn-fcgi一套的理解 词性标注 神经网络概览 微信公众号主动发送消息（针对无法按时回复）","raw":null,"content":null},{"title":"","date":"2016-05-31T15:05:46.000Z","updated":"2016-05-31T15:05:46.000Z","comments":true,"path":"about/sorry.html","permalink":"http://yezhejack.github.io/about/sorry.html","excerpt":"","keywords":null,"text":"对不起很对不起今天早上没有回你信息，看到你的信息的时候我和几个人在一起走，所以就没回，回去之后到了实验室就去看书，推公式推着推着就忘记了。以为我已经回过了，然后你没有发信息过来，我就以为是在忙着预答辩了。我希望我给你带来的是更多的依靠和快乐，而不是这种生气，对不起，下次一定会陪你的。真的很爱你，每次你晚睡、不吃饭我都很心疼的，只是说不出来。我希望我加班的时候你可以早睡觉，不希望你等我，因为我会一直想你。想你还没睡觉，想你要熬夜了。所以还是希望你能按时睡觉，按时吃饭。 爱你","raw":null,"content":null}],"posts":[{"title":"setuptools教程","slug":"setuptools教程","date":"2016-10-11T13:08:36.000Z","updated":"2016-10-11T13:09:30.000Z","comments":true,"path":"2016/10/11/setuptools教程/","link":"","permalink":"http://yezhejack.github.io/2016/10/11/setuptools教程/","excerpt":"","keywords":null,"text":"setuptools 教程基本使用在project目录下创建一个setup.py的文件，其中的内容是 1234567891011121314from setuptools import setup, find_packages setup( name = \"ConvertSubToUTF8\", version = \"0.0.1\", packages = find_packages(), scripts=['ConvertSubToUTF8.py'], install_requires=['chardet&gt;0'], author='Zhe Ye', author_email='yezhejack@gmail.com', description='This is a useful tool for convert sub file code format', keywords='convert sub subtitles files utf8', url='http://yezhejack.github.io/2016/10/11/ConvertToUTF8/', license='PSF',) 然后在目录下运行python setup.py sdist 然后就可以看到目录出现了新的东西","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"}]},{"title":"ConvertToUTF8","slug":"ConvertToUTF8","date":"2016-10-11T12:59:33.000Z","updated":"2016-10-11T12:59:33.000Z","comments":true,"path":"2016/10/11/ConvertToUTF8/","link":"","permalink":"http://yezhejack.github.io/2016/10/11/ConvertToUTF8/","excerpt":"","keywords":null,"text":"This is a small tool for myselfif you have any questions, you can comment on this page","raw":null,"content":null,"categories":[{"name":"My Projects","slug":"My-Projects","permalink":"http://yezhejack.github.io/categories/My-Projects/"}],"tags":[{"name":"Tool","slug":"Tool","permalink":"http://yezhejack.github.io/tags/Tool/"}]},{"title":"numpy常用语句","slug":"numpy常用语句","date":"2016-09-29T07:18:59.000Z","updated":"2016-09-29T16:06:51.000Z","comments":true,"path":"2016/09/29/numpy常用语句/","link":"","permalink":"http://yezhejack.github.io/2016/09/29/numpy常用语句/","excerpt":"","keywords":null,"text":"numpy常用语句矩阵以及向量操作初始化一个向量或者矩阵12import numpy as nptheta=np.array([[1,1,1],[1,1,1]]) 上面的代码初始化了一个2x3的矩阵。 1np.ones((3,4),dtype=int16) 上面的代码初始化了一个3x4的全一矩阵，同时指定了它的类型是int16 转置numpy.transpose() 矩阵乘法12A.dot(B)np.dot(A,B) enp.exp(A) 生成随机数1A=np.random.random((2,3)) 开方1np.sqrt(A) index12b[2,3]b[0:5,1] #这个会获得一个横向量 变换形状1a.reshape(3,-1) 如果某个维度的参数出现了-1，那么这个维度的长度是会自动计算的","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yezhejack.github.io/tags/Machine-Learning/"}]},{"title":"rsync","slug":"rsync","date":"2016-08-23T11:23:36.000Z","updated":"2016-08-25T17:20:08.000Z","comments":true,"path":"2016/08/23/rsync/","link":"","permalink":"http://yezhejack.github.io/2016/08/23/rsync/","excerpt":"","keywords":null,"text":"rsync安装3.1.0版本的rsync为了显示进度条，我需要把我的路径下的rsync更新到3.1.0的版本1wget https://download.samba.org/pub/rsync/src/rsync-3.1.2.tar.gz 如果上述链接失效，则需要到https://rsync.samba.org上 我的使用方法12rsync -a --progress -h -e 'ssh -p 55555' --partial zye@202.118.250.16:/data/ltp/ltp-models backup/rsync -a --progress -h -e 'ssh -p 55555' --partial backup rsync@180.168.92.130:/volume1/hpc_data 如果在源地址后面加上斜杠的话，就只是表示拷贝下面的内容 介绍rsync是一个快速的、多用途的文件拷贝工具。它可以实现本地的、远程的。两种远程方式，一个是通过rsync服务，一个是通过ssh服务。它提供了很多的选项来控制它的每一种行为和定义需要拷贝的文件。它因为它的增量拷贝算法而著名。广泛用于备份和镜像，并且作为一个改进的拷贝命令作为日常使用。 rsync可以找得到需要传输的文件，这是基于一个快速的检查算法（默认），它检查那些大小和最后修改时间有变化的文件。其他有变化的被保留的属性也会作用到目标文件上，如果快速检查表明文件的数据并不需要更新。 一些特点 支持拷贝链接、设备、所有者、所有组和权限 排除机制 一个版本控制可以忽略的机制 可以使用shell来传输，比如ssh rsh 不需要超级用户权限 管道传输，减少延迟消耗 支持匿名或者验证的rsync守护进程 总体rsync可以把文件拷到或从远程主机拷贝，或者只在本地拷贝。（它无法在两个远程主机之间拷贝文件）。 rsync有两种方法和远程系统通讯：使用一个远程shell程序作为传输的工具（比如ssh或rsh）或者通过TCP协议直接和rsync守护进程连接。远程shell传输在主机名后面使用单个（:）的时候，远程shell传输会被使用。当使用（::）的时候或者用rsync:// URL的时候才会直接使用rsync守护进程来通讯。 如果没有目的地址的话，文件只会被列出来，像ls -l一样。 同样的，如果源地址和目的地址都不是远程主机上的话，那么拷贝的行为只会发生在本地。 rsync的本地是作为客户端的，远程端是作为服务器端。不要将服务器和一个rsync守护进程搞混了。一个守护进程肯定是一个服务，但是一个服务可以是一个守护进程也可以是一个远程shell生成的一个进程。 设置一旦安装好了之后，你就可以对任意你能够通过远程shell登陆的主机使用rsync（包括那些你能用rsync守护进程模式协议登陆的主机）。对于远程传输，一个现代的rsync使用ssh来进行通讯，但是它可以被配置去使用一个别的远程shell，比如rsh或remsh 你能指定任何你喜欢的远程shell，可以通过使用-e这个命令行选项或者设置RSYNC_RSH环境变量。 注意，rsync必须在源主机和目的主机上都安装好。 使用你可以按照rcp的方法来使用rsync，指定一个源地址和目的地址 1rsync -t *.c foo:src/ 这个会把同模式*.c匹配的文件都拷贝到机器foo去。如果有个文件已经有了，那么rsync远程更新的协议就会涌来更新这个文件。 1rsync -avz foo:src/bar /data/tmp 这个命令可以将src/bar这个文件夹下的所有内容都传输到/data/tmp/bar文件夹中。这些文件是在archive模式下传输的，这个会保证软链接、设备、属性、权限和所属等都被保留下来。另外，压缩也会在传输中被使用。 1rsync -avz foo:src/bar/ /data/tmp 相比于上面多出现的一个斜杠可以避免拷贝的时候在目的地多出现一层文件结构。你可以这样来认为，多加一个斜杠在源地址表明了拷贝这个目录的内容，而不是按照名字拷贝目录，但是无论哪种，这些文件夹的属性都会用相同的方式传输过去。下面两个命令做的事情是一样的 12rsync -av /src/foo /destrsync -av /src/foo/ /dest/foo 但是对于指向主机或者模块的地址，并不要求一个斜杠来拷贝默认文件夹的内容，比如，下面两个例子就都是把文件的内容拷贝到/dest中: 12rsync -av host: /destrsync -av host::module /dest 你可以使用本地模式的rsync，就是其中的两个地址都不带有:。就像一个改进过的拷贝命令。 1rsync somehost.mydomain.com:: 这个可以列出所有可用的模块。 高级用法可以给出多个源地址，和前面host相同的可以忽略 123rsync -av host:file1 :file2 host:file&#123;3,4&#125; /dest/rsync -av host::modname/file&#123;1,2&#125; host::modname/file3 /dest/rsync -av host::modname/file1 ::modname/file&#123;3,4&#125; 老版本的rsync要求对于源地址加上单引号 如果需要传输一个带有空格的文件名，你可以使用--protect-args(-s)选项或者你可以加\\。比如 1rsync -av host:`file\\ name\\ with\\ spaces` ／dest 连接一个rsync守护进程这个时候使用的是一个监听873的TCP接口，这个当然需要守护进程在远程服务器上运行着。 你可以试使用双冒号来代替但冒号来分割主机名和路径，或者使用rsync://URL。 path的第一个词是一个模块名字 远程守护进程能够打印一个当天的信息，当你连接的时候 如果没有指定路径名字，那么就会列出能够访问的路径 如果没有指定目的地址，那么就会列出匹配的文件 不能指定--rsh(-e)选项 一个拷贝远程主机中模块src中的所有文件的例子 1rsync -av host::src /dets 如果需要认证的话，你会被要求输入密码。你可以设置一个RSYNC_PASSWD的环境变量来避免这个过程。或者使用--password-file，这个方法对于在脚本中使用rsync有用。 在某些系统中，环境变量对所有用户都是可见的，在这种系统中，推荐使用--password-file。 设置环境变量RSYNC_PROXY来进行代理，格式为hostname:port。这个代理必须能够支持对端口873的连接。 可以通过设置环境变量RSYNC_CONNECT_PROG为代理命令。 通过远程shell连接使用rsync-daemon功能rsync支持使用一个远程shell连接，然后启动一个守护服务，这个服务会读取在home地址下的配置文件。这个主要是可以加密那些daemon-style的传输数据。另一种加密一个守护传输的，可以考虑使用ssh来加密一个本地借口到远程机器，然后配置一个rsync服务，只允许来自localhost的连接。 需要明确地设置远程shell程序，用--rsh==COMMAND选项。在环境变量中设置RSYNC_RSH并不会打开这个功能。例如 1rsync -av --rsh=ssh host::module /dest 可以指定ssh的用户 1rsync -av -e \"ssh -l ssh-user\" rsync-user@host::module /dest ssh-user会被用于ssh的登陆，而rsync-user会被用于模块的登陆 可以对传输顺序排序rsync会把指定的文件名放入它内部的传输列表中，并排序。这个可以快速地筛除同名文件，会跟用户给出的文件顺序不同。 选项 --msgs2stderr 这个选项会把所有信息输到stderr，如果没有--remote-option 比如-M--msgs2stderr -I --ignore-times 同样大小的，但是时间不同的也会被略去 --no-motd会影响使用rsync host::来列出所有模块，未理解 --size-only只看文件大小来确定文件是否需要传输 -@,--modify-window默认是0，是看两个时间戳之间的差值，小于这个选项所给的值则认为相等。如果是正数则表示的单位是秒，如果是负数，表示的单位是纳秒。对于MS Windows FAT文件系统，需要设置为1. -c --checksum 确保文件是被修改过的，而不是采用快速检查修改时间和大小。 -a --archive 是一个快速模式，告诉rsync基本上你什么都想保留，除了硬连接。 --no-OPTION用来关闭前面已经生效的选项，只可以是那些被整合进别的选项的选项，或者实在不同时候有不同默认值的选项。可以用长或短的格式，比如--no-R和--no-relative是一样的。这个选项的顺序是非常重要的。比如要关闭-a中带来的-r，就得把--no-r放在-a的后面，否则无法关闭。 -r --recursive 可以递归地传输目录，在3.0.0版本会使用一个增量的扫描方法，这个方法减少了非常多的在传输前所需要的内存空间。并且传输在扫描了一些文件夹之后就开始了。这个增量扫描只影响了递归算法，对于非递归的不影响。如果想要使用的话必需保证传输的两端的rsync版本是3.0.0。 -R --relative 可以保留路径的信息，比如rsync -av /foo/bar/baz.c remote:/tmp/会在/tmp/下新建一个叫做baz.c的文件，但是rsync -avR /foo/bar/baz.c remote:/tmp/则会在/tm//foo/bar建立一个新的baz.c --no-implied-dirs 会影响-R的默认行为。当这个被打开的时候，前面被提到的目录的属性不会被传输过去。如果有新的目录被创建，那么就会是默认的属性，已有的目录的属性不变。 -b,--backup这个选项之前已经存在的目标文件会被转移走或者被删除。 --backup-dir=DIR它告诉--backup选项把备份存在哪里，这可以用于增量备份，但是这个不可以跑到模块外面去。 --suffix=SUFFIX用来表示--backup的前缀 -u,--update这个会跳过所有已经存在的并且修改时间更新的。 --inplace 可以将数据直接写到文件的位置上，但它有几个影像，一个是硬连接会被保留，二是在使用的二进制包不能被改写，三是文件容易出现不一致。一个rsync无法写的文件将不会被更新。 --append 这个会用追加的方式来更新文件，但是对于那些可能不是从尾部更新的文件，这个会导致错误。 --append-verity会校验一下追加更新的文件，如果校验失败，则回退。* --chmod可以用来修改文件的读写权限。 --owner这个选项可以用来保证传过去的文件的所有者和源文件是一样的 --super这个选项会告诉接收端尝试使用超级用户权限。 --existing,--ignore-non-existing是告诉rsync跳过需要创建的文件 --ignore-existing用来告诉rsync跳过那些已经存在的文件 --temp-dir=DIR 可以设置一个临时的文件夹来存储正在拷贝的文件，有利于在磁盘空间不够的时候，将临时文件设置在另一个磁盘上。 --partial-dir=DIR 设置一个临时文件夹用于断点续传，但是它并不开启断点续传 --partial开启断点续传 --delay-updates当文件全部传完了之后再把文件放到目的位置，这样可以使操作显得原子。这个选项与--partial冲突。 --info=FLAGS可以显示特定的信息，比如--info=progress2可以显示整体传输的进度。","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"rsync","slug":"rsync","permalink":"http://yezhejack.github.io/tags/rsync/"}]},{"title":"iptables","slug":"iptables","date":"2016-08-22T17:10:23.000Z","updated":"2016-08-22T17:10:25.000Z","comments":true,"path":"2016/08/23/iptables/","link":"","permalink":"http://yezhejack.github.io/2016/08/23/iptables/","excerpt":"","keywords":null,"text":"iptables 设置使用的方法将输出的包重定向1iptables -t nat -A OUTPUT -p tcp -d 192.168.1.107 --dport 5001 -j DNAT --to-destination 192.168.1.107:5000 这是把本来发往192.168.1.107:5001端口的包发往192.168.1.107:5000 这里是为了解决一个问题，就是一个NAS的NFS服务器需要一个111端口来进行挂载，但是似乎nfs没有提供可配置选项，如果我们在一个路由器后放上多个NAS的话怎么办，因此需要又一个办法让发出去的111端口重新定位到不同的端口上去，然后再将这个端口转发到111上。","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"iptables","slug":"iptables","permalink":"http://yezhejack.github.io/tags/iptables/"}]},{"title":"非递归遍历二叉树","slug":"非递归遍历二叉树","date":"2016-08-16T17:11:06.000Z","updated":"2016-08-17T11:02:30.000Z","comments":true,"path":"2016/08/17/非递归遍历二叉树/","link":"","permalink":"http://yezhejack.github.io/2016/08/17/非递归遍历二叉树/","excerpt":"","keywords":null,"text":"非递归遍历二叉树先根遍历对于递归来说，有一个很大的特征，就是先访问到的函数需要越晚结束掉。因此这就对应上栈这种数据结构。对于先根遍历来说递归函数是这样写的 12345dg(root)&#123; fangwen(root); dg(root-&gt;left); dg(root-&gt;right);&#125; 每次都需要把root入栈，因为只有这样才能找到左右儿子。因此对于当前节点P，先对其进行访问，然后把P入栈，然后再去访问P的左儿子，等到左儿子全都访问完毕后，会从栈里弹出P，从而找到右儿子。因此，有左儿子的情况下，需要把P入栈（之前访问过了），然后将P设为左儿子，从而进入左子树。 如果没有左儿子的话，就去看右儿子，由于已经找到右儿子，所以就不需要把当前节点P入栈了，直接将P设成当前节点的右儿子。 如果没有右儿子的话，则继续弹出，直到有右儿子为止，或者栈弹空了。 中根遍历递归的写法 12345dg(root)&#123; dg(root-&gt;left); fangwen(root); dg(root-&gt;right);&#125; 可以看出来，我们将root也就是P放进栈，是为了到时候拿出来进行访问，并且需要从而进入右儿子。 对于当前节点P，如果它有左子树的话，则将其入栈，并且将P=P-&gt;left 如果它没有左子树，则对其进行访问。如果有右子树，则将P设置为P=P-&gt;right。如果也没有右子树的话，则从栈里再弹出一个元素，并设置为P。 后根遍历递归的写法12345dg(root)&#123; dg(root-&gt;left) dg(root-&gt;right) fangwen(root);&#125; 入栈是为了找到右子树和访问中间节点。因此只有第二次出现在栈顶的时候（进去的时候不算）才能被弹出，第一次是为了找到右节点，第二次是为了访问。 因此对于当前的P，如果它有左子树，则将其P-&gt;record=0，然后P=P-&gt;left，如果没有左子树，则将其P-&gt;record=1，然后P=P-&gt;right。record=0表示还没出现在栈顶过，如果是1则表示左边已经不需要考虑，发现等0则不需要弹栈，如果等1，则需要弹栈 无左有右的情况下，需要把record设为1，然后将当前节点设置为P=P-&gt;right 无左无右的情况下，直接访问当前节点，然后弹出一个。如果P-&gt;record=1，则访问这个P，然后接着弹，直到一个P-&gt;record==0或者弹空，等0的时候，则将其设置为1，再放入栈里，然后再将P设置为它的右儿子。","raw":null,"content":null,"categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://yezhejack.github.io/categories/leetcode/"}],"tags":[{"name":"Tree","slug":"Tree","permalink":"http://yezhejack.github.io/tags/Tree/"}]},{"title":"pyspider爬虫框架源码阅读","slug":"pyspider爬虫框架源码阅读","date":"2016-07-30T13:53:58.000Z","updated":"2016-08-02T12:19:39.000Z","comments":true,"path":"2016/07/30/pyspider爬虫框架源码阅读/","link":"","permalink":"http://yezhejack.github.io/2016/07/30/pyspider爬虫框架源码阅读/","excerpt":"","keywords":null,"text":"pyspider爬虫框架源码阅读主要使用的组件tornado一个异步可并发的网络库 有4个部分组成 Web Framework，RequestHandler HTTP的客户端和服务端 HTTPServer AsyncHTTPClient 一个异步的网络库 IOLoop IOStream 一个协程库 tornado.gen flask用于搭建web server phantomjs用于爬取js页面 click用于建立一个好的命令行接口的库 1@click.command() 表示这是一个子命令。 1@click.option 表示一个命令行的option 1@click.option('--shout/--no-chout',default=False) 表示这是一个boolean flag 12@click.command()@click.option('--hash-type',type=click.Choice(['md5','sha1'])) 这两个装饰器会对hash-type这个参数进行检查，如果不是之一的话，会报错。123456#### prompt ####当用户没有指定一些参数的时候，让程序去追问用户，叫做prompt parameters#### 从环境变量中读取值 ####有两种方式，一种是从环境变量中读取自定义的 @click.command()@click.option(‘–username’)def greet(username): click.echo(‘hello %s!’ % username) if name==’main‘: greet(auto_envvar_prefix=’GREETER’)12然后在命令行中 $ export GREETER_USERNAME=john$ greethello john1#### 可变参数 #### @click.command()@click.argument(‘src’,nargs=-1)@click.argument(‘dst’,nargs=1)123这样子src就拥有了可变参数的特性，可以吃掉任意多的参数。但是只能有一个可变参数存在。如果想要至少提供一个参数的可变参数的话，需要设置```requeired=True 文件安全提供了lazy mode和atomic mode来保证文件的读写安全，lazy模式下，读文件会得到立即的反应，而写文件则会到第一次IO操作的时候才有反应。 复杂应用上下文环境 context当一个click命令执行的时候，一个12环境对象建立一个链接表，直到他们到达了最上面的一个。每个环境都会和它的父环境链接。这样子，每个环境对象都能够保存自己的信息，而不用担心会影响到其他命令的状态了。同时也保证了当父环境的数据需要读取的时候，可以到达。 @click.pass_context1可以将上下文传输过来 @click.pass_obj则是只传递Context.obj```字段过来。 当使用了这两个装饰器之后，被装饰的函数的第一个参数就是对应的Context或Context.obj run.py在./pyspider/run.py中从cli()函数开始运行,看之前最好看一下click的使用，因为整个结构是基于click的。 lambda 匿名函数这个是用来绑定一个匿名函数的","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yezhejack.github.io/tags/爬虫/"},{"name":"pyspider","slug":"pyspider","permalink":"http://yezhejack.github.io/tags/pyspider/"}]},{"title":"前端","slug":"前端","date":"2016-07-28T03:58:32.000Z","updated":"2016-07-30T01:39:02.000Z","comments":true,"path":"2016/07/28/前端/","link":"","permalink":"http://yezhejack.github.io/2016/07/28/前端/","excerpt":"","keywords":null,"text":"isLogin:function({})这个是在函数前加上一个函数名，实际上就是定义一个叫做isLogin的函数。 多个class在html中，给一个对象附上多个class的方法是，在class=””中用空格隔开，比如class=”a b”，那么它就有两个class的标签了，一个是a，一个是b。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"js","slug":"js","permalink":"http://yezhejack.github.io/tags/js/"},{"name":"javascript","slug":"javascript","permalink":"http://yezhejack.github.io/tags/javascript/"}]},{"title":"Hadoop I/O","slug":"Hadoop I:O","date":"2016-06-25T19:07:30.000Z","updated":"2016-06-28T13:04:29.000Z","comments":true,"path":"2016/06/26/Hadoop I:O/","link":"","permalink":"http://yezhejack.github.io/2016/06/26/Hadoop I:O/","excerpt":"","keywords":null,"text":"Hadoop I/Ohadoop提供了多种的解压缩方式，但是由于license的问题，得单独下载。 hadoop同时也对文件读写有校验，一旦出现文件错误，就会报告给namenode，namenode则不会再给别的任务派送这个文件块，同时调度其他的replica来恢复。 每个datanode会定期地检查自己的数据。 使用本地的库来进行压缩或解压可以节省很多时间，相对于通过Java实现的来说。几乎所有的压缩方式都有本地的实现，而有的则没有Java的版本。 Apache Hadoop打包好的二进制的hadoop版本，包含了一个libhadoop.so的压缩包。这个版本只为64-bit Linux。其他的平台则要自己编译一个。默认的，Hadoop会寻找本地版本的库来使用，因此不需要去改变配置来使用本地的库。而有的时候你想要关闭本地的库，则需要将io.native.lib.available设置为false。 如果使用了很多的压缩和解压缩的话，可以使用CodecPool来复用压缩器和解压缩器。 压缩与输入切分一个1GB的未压缩的文件存储在HDFS中，会被存储在8个block中，一个使用这个文件的MR任务会使用八个任务来处理这些输入。而如果是gzip压缩的话，无法从任意一个文件偏移开始读取gzip流，因此无法分成8个来分开处理。只能用一个map来串行地处理这个8个输入。MR会根据扩展名来判断，不用担心。这就牺牲了本地化。同时粒度也小了，就需要更长的时间去运行了。 具体什么的压缩格式比较合适，应该选用支持切分的。 通过设置mapreduce.output.fileoutputformat.compress为true，设置mapreduce.output.fileoutputformat.compress.codec为需要使用的压缩codec。 因为map的输出结果需要很大的网络开销，所以可以使用一些能够快速压缩的格式，来压缩map的输出 序列化序列化石把结构化的数据转换为一个字节流，这样可以在网络中传输，或者用于持久化存储。在分布式系统中主要用于进程间的通讯和持久化存储。 需要几个特点，一个是compact，这样可以充分利用带宽资源，另一个是快速，还有可扩展性，最后还有一个就是可内部操作。Hadoop使用了自己特有的序列化格式，只能在Java中使用，而Avro也是一个序列化的系统，用来克服专有格式带来的一些限制。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yezhejack.github.io/tags/hadoop/"},{"name":"big data","slug":"big-data","permalink":"http://yezhejack.github.io/tags/big-data/"}]},{"title":"YARN","slug":"YARN","date":"2016-06-24T08:19:33.000Z","updated":"2016-06-25T19:06:52.000Z","comments":true,"path":"2016/06/24/YARN/","link":"","permalink":"http://yezhejack.github.io/2016/06/24/YARN/","excerpt":"","keywords":null,"text":"YARN简介YARN在hadoop 2中被引入，用于改善MapReduce，但是它也被用于支持别的计算框架。YARN提供API用于请求和使用集群资源，但这些不是直接被用户的代码使用的。 如何工作的YARN通过两种守护进程来提供它的核心服务，一个是resource manager，另一个是node managers。后者会启动和监控containers。一个container会执行一个特定程序的进程，同时包括一系列的受限制的计算资源。一个container可以是一个unix的进程，或者是linux的cgroup。 本地化是可以让集群的带宽的利用率达到最大。通常情况下，会在存有数据的node上启动，再不行就在同一个rack上启动，再不行就随机任意一个node。 Spark是事先就申请好固定的资源用于计算，而MapReduce则是动态地，先为map申请资源，然后再为reduce申请资源。 应用生命周期 一种模型是每个用户job一个应用，MapReduce采用的就是这样 第二个是每个流程或用户对话一个应用，这个更高效，因为container可以复用，Spark采用的是这种。 第三种模型是长期运行的、被用户共享的应用。这种应用的好处在于反应快。 建立YARN应用Slider可以用来直接启动已有的应用在YARN上。 Apache Twill也是类似于Slider。 MapReduce 1中有jobtracker和多个tasktracker来控制job的执行，其中jobtracker负责任务的调度以及任务的监控（失效重启等）。 MapReduce 1中的jobtracker对应着yarn中的 Resource Manager、application master和timeline server，而tasktracker对应着node manager，slot对应着Container YARN最大的好处在于它不再只为MapReduce使用，它可以为很多别的计算框架提供服务。 YARN调度提供了三种scheduler FIFO Capacity Fair Scheduler 但是FIFO会导致小任务被大任务阻挡，Capacity Scheduler有专用队列，每个队列有它的容量，这个容量表示它所能给队列中的任务分配的最大计算资源。但是在有空余资源的情况下，系统是有可能给队列中等待的资源分配一个大于它的容量的计算资源。它不会通过杀死其他Container来抢占资源，所以当自己的计算资源被弹性队列机制拿走的时候，它也只能等着别的队列用完之后换给它。为了避免这个情况，是可以配置一个最大容量，如果没配置则有可能会用光这一级的所有资源。 Fair Scheduler则是让每次新来的任务都从前一个任务中分出一半的资源。 延迟调度为的是能够增大在本地运行的机会","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yezhejack.github.io/tags/hadoop/"},{"name":"big data","slug":"big-data","permalink":"http://yezhejack.github.io/tags/big-data/"}]},{"title":"HDFS","slug":"HDFS","date":"2016-06-23T02:49:58.000Z","updated":"2016-06-25T19:06:53.000Z","comments":true,"path":"2016/06/23/HDFS/","link":"","permalink":"http://yezhejack.github.io/2016/06/23/HDFS/","excerpt":"","keywords":null,"text":"HDFS 学习HDFS文件系统具有高容错率，每个block的size为128MB，为的是减少寻址时间。整个hadoop集群中分为了Namenode和Datanode，其中Namenode保存着metadata，也就是整个HDFS文件系统的树和块信息。而Datanode则负责具体block的存取，并且周期性地向Namenode报告它所拥有的数据块。 datanode自身因为会把block复制几遍，所以已经有了容错机制了。而namenode则可以将metadata持久化到其他的文件系统中，或者运行一个secondary namenode。这个secondary namenode的主要作用是不断地合并log，避免log文件过大。但是由于这两个namenode之间还是有延迟的，所以数据的丢失是肯定的。在主要的namenode失效的情况下的做法通常是将文件系统中的metadata拷贝到secondary namenode中，让它作为primary namenode。 HDFS结合可以以有多个namenode，分管一部分namespace。 HDFS高可用性namenode失效恢复机制 装载命名空间镜像到内存 重现编辑log 接受足够多的块报告，以便离开安全模式 这个通常会花费超过30mins的时间。因此有计划的宕机更重要。Hadoop 2通过增加高可用性来解决了这个问题。通过增加一个随时待命的namenode。而这个standby的namenode也将secondary namenode的职责也承担下来了。 故障转移从激活的namenode转移到standby namenode需要failover controller。需要许多的failover controller来 fencing用于保证下线的namenode不会造成数据冲突 QJM一次只允许一个namenode往编辑log里写东西。然而，之前的namenode还是会为旧的客户请求提供服务，因此需要设置一个SSH fencing command来杀死这个namenode的进程。更激进的fencing方法用于NFS共享log。因为不可能只让每时刻只有一个namenode写log。这也是为什么QJM是被推荐的。一个方法是取消这个namenode访问共享存储目录的权限，关闭它的网络接口。最后的招数是直接击毙这个节点，也就是关闭电源。而客户端会逐个尝试配置文件中的namenode address。 命令行接口有两个属性需要设置 1fs.defaultFS=hdfs://localhost/ HDFS守护进程会使用这个东西去查找HDFSnamenode的地址和端口。HDFS clients也会通过这个查找namenode。 另一个属性是1dfs.replication=1 这样HDFS就不会讲每个块都复制三遍了。当只有单个datanode的时候，HDFS无法复制三遍，所以会不停地警告，这个设置会解决这个问题。 基本操作12hadoop fs -copyFromLocal input/docs/quangle.txt \\hdfs://localhost/user/tom/quangle.txt 如果查找不到datanode的话12sudo rm -R /tmp/*hdfs namenode -format 然后重启 hdfs client读文件过程 客户端先打开一个FileSystem对象，对于HDFS文件系统来说是DistributedFileSystem。它会返回前几个block的地址。同时这些地址，也就是datanode的地址，会根据它们的拓扑情况排序。除此之外，还会返回一个FSDataInputStream，其中包含着一个DFSInputStream。 客户端通过read()来读取文件，在DFSInputStream中保存着datanode的地址，DFSInputStream会一块一块地读取文件，但是客户端只会觉得是从一个流里面读取数据。当这一批的block都读取完了，它会向namenode请求下一批block的地址。当结束的时候，它会调用call()。 如果DFSInputStream在和datanode通讯的时候遇到了错误，那么它会记录这个datanode是坏掉的，然后会尝试别的datanode。 这个过程中namenode只是回复查询块位置的请求。 网络拓扑和Hadoop通过计算两个节点到它们最近的共同祖先的距离。 同一个节点的距离 &lt; 同一个机架的两个不同节点 &lt; 同一个数据中心，不同机架的两个节点 &lt; 不同数据中心的两个节点 hdfs client 写文件的过程 客户端在DistributedFileSystem上调用create() DistributedFileSystem向namenode调用并创建一个文件在命名空间里，但是并没有实际的blocks和它联系在一起。 namenode会运行多种检查来确保文件并不是已经存在的，并且用户有足够的权限去创建这个文件。如果检查通过了，那么namenode会为这个文件创建一个记录。如果失败了，则会抛出IOException。 成功之后，DistributedFileSystem会返回一个FSDataOutputStream，用于客户端写数据。正如读过程一样，FSDataOutputStream包着一个DFSOutputStream。它负责和datanode和namenode的通讯。 DFSOutputStream会把数据分成好几份，然后放在一个queue中，然后会有若干个datanode在等待，如果是将每个block复制三遍的话，则会想给第一datanode，然后第一个datanode再给第二个datanode，然后第二个datanode再给第三个datanode。 DFSOutputStream还会维护一个ack queue，只有当一个packet的所有datanode都表示回复了ack之后，才会从这个queue中移除。 hdfs是如何选择节点去存储一个block的它优先选一个client在的节点，如果是外部请求，则随机一个。第二个拷贝会换一个rack，第三个会放在和第二个拷贝的相同机架上，但是在不同的节点。后面的拷贝则是在集群中随机选择。 FSDataOutputStream中的hflush强制让缓存中的数据写到datanodes中，并且让其是对外可见的，但是这个只是保证到达了datanode的内存中，如果掉电了，还是会存在数据丢失的情况。hsync()是一个更强的保证，保证数据已经写到文件中了。 关闭一个HDFS中的文件，就隐式地调用了hflush hdfs的路径问题在hdfs-site.xml中设置，否则会放在tmp文件夹下，但是如果设置了tmp文件夹的话也就没什么关系了。因为tmp会定时删除。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yezhejack.github.io/tags/hadoop/"},{"name":"big data","slug":"big-data","permalink":"http://yezhejack.github.io/tags/big-data/"}]},{"title":"最大熵模型","slug":"最大熵模型","date":"2016-06-13T13:10:00.000Z","updated":"2016-06-13T13:34:19.000Z","comments":true,"path":"2016/06/13/最大熵模型/","link":"","permalink":"http://yezhejack.github.io/2016/06/13/最大熵模型/","excerpt":"","keywords":null,"text":"最大熵模型解决的两个问题 What exactly is meant by “uniform”, and how can we measure the uniformity of a model Having determined a suitable answer to these questions, how do we go about finding the most uniform model subject to a set of constrainsts. 当没有足够的信息去判断两个事件的可能性谁更大的时候，最好的策略是将它们认为是相等的。 $p(y|x)$是一个条件概率 feature 和 constraint的区别 feature是指二元的函数 constraint则是一个等式，也就是特征函数在模型中的期望值和在训练数据中的（经验期望）的等式。","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yezhejack.github.io/tags/Machine-Learning/"},{"name":"Maxent","slug":"Maxent","permalink":"http://yezhejack.github.io/tags/Maxent/"},{"name":"Maximum Entropy Method","slug":"Maximum-Entropy-Method","permalink":"http://yezhejack.github.io/tags/Maximum-Entropy-Method/"}]},{"title":"支持向量机","slug":"支持向量机","date":"2016-06-12T12:10:00.000Z","updated":"2016-06-12T16:23:48.000Z","comments":true,"path":"2016/06/12/支持向量机/","link":"","permalink":"http://yezhejack.github.io/2016/06/12/支持向量机/","excerpt":"","keywords":null,"text":"第七章 支持向量机7.1线性可分支持向量机与硬间隔最大化7.1.1线性可分支持向量机一般的，当训练数据集线性可分时，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个，线性可分支持向量机利用间隔最大化求最优分离超平面，这时，解时唯一的。 定义7.1（线性可分支持向量机） 超平面 $w^{*} \\cdot x+b^{*}=0$ 决策函数 $f(x)=sign(w^{*} \\cdot x +b^{*})$ 7.1.2 函数间隔和几何间隔定义函数间隔 $\\hat{\\gamma_i}=y_i(w \\cdot x_i+b)$超平面(w,b)关于训练数据集T的函数间隔为超平面(w,b)关于T中所有样本点的函数间隔的最小值。为了统一标准，引入几何间隔概念。$\\gamma_i=y_i(\\frac{w}{||w||} \\cdot x_i+\\frac{b}{||w||})$ 7.1.3 间隔最大化支持向量机学习的基本思想是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。这里的间隔最大化又称为硬间隔最大化。 这个问题可以表述为下面的约束最优化问题 $$\\max_{w,b} \\gamma \\\\ s.t. y_i(\\frac{w}{||w||} \\cdot x_i+\\frac{b}{||w||}) \\geq \\gamma,i=1,2,...,N$$","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yezhejack.github.io/tags/Machine-Learning/"},{"name":"Support Vector Machine","slug":"Support-Vector-Machine","permalink":"http://yezhejack.github.io/tags/Support-Vector-Machine/"}]},{"title":"Stanford NLP 笔记","slug":"NLPofStanford","date":"2016-06-11T10:00:00.000Z","updated":"2016-06-11T15:36:28.000Z","comments":true,"path":"2016/06/11/NLPofStanford/","link":"","permalink":"http://yezhejack.github.io/2016/06/11/NLPofStanford/","excerpt":"","keywords":null,"text":"Generative vs Discrimnative Models这是两种模型，分别是使用了Joint Prob. 和 Conditional Prob. 也就是实用P(class,data)和P(class|data)的区别。","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"Coursera","slug":"Coursera","permalink":"http://yezhejack.github.io/tags/Coursera/"}]},{"title":"第五章－神经网络学习","slug":"第五章－神经网络学习","date":"2016-05-29T14:16:00.000Z","updated":"2016-05-31T07:27:55.000Z","comments":true,"path":"2016/05/29/第五章－神经网络学习/","link":"","permalink":"http://yezhejack.github.io/2016/05/29/第五章－神经网络学习/","excerpt":"","keywords":null,"text":"神经网络5.1 神经元模型M-P神经元模型：$y=f(\\sum_{i=1}^{n}w_i x_i - \\theta)$ 最后还需要一个激活函数来处理并产生神经元的输出。因为以阶跃函数作为激活函数的话，其具有不连续、不光滑等不太好的性质，因此通常使用Sigmoid函数作为激活函数。它把可能在较大范围内变化的输入值挤压到（0，1）输出值范围内，因此有时也称为挤压函数（squashing function）。 把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。 5.2 感知机与多层网络感知机（Perceptron）由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，亦称阈值逻辑单元（thresholod logic unit）。 感知机能容易地实现与、或、非运算。这个可以通过手工设定参数$w$和$\\theta$。更一般的应该是能够给定数据集，然后权重$w_i$以及阈值$\\theta$可以通过学习得到。阈值$\\theta$可以看作一个规定输入为-1.0的哑节点(dummy node)所对应的连接权重$w_{n+1}$。 学习规则 对于训练样例$({\\bf x},y)$，若当前感知机的输出为$\\hat{y}$，则感知机权重将这样调整： $w_i \\leftarrow w_i+\\Delta w_i$$\\Delta w_i = \\eta (y-\\hat(y))x_i$ 当$y=\\hat{y}$的时候，感知机的学习结束，权重不再调整。只有当两类模式是线性可分的，即存在一个线性超平面能将它们分开，则感知机的学习过程一定会收敛（converge），但是如果不是线性可分的，例如要模拟一个异或的话，因为其线性不可分，所以无法模拟。因为感知机只有输出层神经元进行激活函数处理。 要解决非线性可分的问题，就需要使用多层功能神经网络。比如一个简单的两层感知机就能解决异或问题。输入层和输出层之间加入一层神经元，这一层被称为是阴层（隐含层 hidden layer），隐含层和输出层神经元都是拥有激活函数的功能呢神经元。 每层神经网络与下一层神经网络全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络通常称为多层前馈神经网络（multi-layer feedforward neural networks），其中输入层神经元仅接收外界输入。前馈并不意味着网络中的信号不能向后传，而是指网络拓扑结构上不存在环或回路。 5.3 误差逆传播算法误差逆传播算法（error BackPropagation）简称BP算法可以用来学习一个神经网络模型。其不仅可以用于多层前馈神经网络，还可以用于其他类型，例如训练递归神经网络，但通常说的BP网络指的是用BP算法训练的多层前馈神经网络。 对训练样例$(x_k,y_k)$来说，假定神经网络的输出为${\\bf {\\hat{y_j^k}}}=(\\hat{y}_1^k,\\hat{y}_2^k,...,\\hat{y}_l^k$即 ${\\bf {\\hat{y_j^k}}}=f(\\beta_j-\\theta_j)$ 则网络在$(x_k,y_k)$上的均方误差为 $E_k =\\frac{1}{2} \\sum_{j=1}^{l} (\\hat{y_j^k}-y_j^k)^2$ 这里的$\\frac{1}{2}$是为了后续求导方便。 网络中的参数个数，从输入层到隐层，因为只有权值，所以有$d \\times q$个权值，从隐层到输出的权值也有$q \\times l$个，然后还有 $q$个隐层的阈值，$l$个输出层的阈值。 任意参数$v$的更新估计公式为 $v \\leftarrow v + \\Delta v$ BP算法基于梯度下降策略，以目标的负剃度方向对参数进行调整。 $\\Delta w_h^j =-\\eta \\frac{\\partial E_k}{\\partial w_h^j}$ 简单推导一下 $\\Delta w_h^j =-\\eta \\frac{\\partial E_k}{\\partial w_h^j}=\\frac{\\partial E_k}{\\partial \\hat{y_j^k}} \\cdot \\frac{\\partial \\hat{y_j^k}}{\\partial \\beta_j} \\cdot \\frac{\\partial \\beta_j}{\\partial w_h^j}$ 再根据$\\beta_j$的定义（看图），显然有 $\\frac{\\partial \\beta_j}{\\partial w_h^j}=b_h$ 下面要解决前面两个偏导。我们知道理想的激活函数是Sigmoid函数 $sigmoid=\\frac{1}{1+e^{-x}}$ 这个函数有一个很好的特性 $f\\prime (x)=f(x)(1-f(x))$ 利用Sigmoid函数的特性，以及前面求得的 $$\\hat{y_j^k}=f(\\beta_j-\\theta_j) \\\\ E_k=\\frac{1}{2} \\sum_{j=1} (\\hat{y_j^k} - y_j^k)$$ 可以得到 $$g_j=- \\frac{\\partial E_k}{\\partial \\hat{y_j^k}} \\cdot \\frac{\\partial \\hat{y_j^k}}{\\partial \\beta_j} \\\\ ＝-(\\hat{y_j^k}-y_j^k)f\\prime(\\beta_j-\\theta_j) \\\\ =\\hat{y_j^k}(1-\\hat{y_j^k})(y_j^k-\\hat{y_j^k})$$ 这里我们得到了隐含层到输出层的权值的更新公式 $\\Delta w_h^j=\\eta g_j b_h$ 除此之外我们还有三种参数需要更新，分别是$\\theta v \\gamma$。 书中没有给出具体的推导，但是我们可以来自己算一下。首先是$\\theta$ $$\\begin{align} \\theta_j&amp;=\\theta_j - \\frac{\\partial E_k}{\\partial \\theta_j} \\\\ \\frac{\\partial E_k}{\\partial \\theta_j}&amp;= \\frac{\\partial E_k}{\\partial \\theta_j} \\cdot \\frac{\\partial \\hat{y_j^k}}{\\partial \\theta_j} \\\\ &amp;=-(\\hat{y_j^k} - y_j^k) \\cdot -f\\prime(\\beta_j-\\theta_j) \\\\ &amp;=(\\hat{y_j^k} - y_j^k)\\hat{y_j^k}(1-\\hat{y_j^k}) \\\\ &amp;=g_j \\end{align}$$ 所以呢 $\\Delta \\theta_j=-\\eta g_j$ 下面再说$v_ih$和$\\gamma_h$ $$\\begin{align} e_h &amp; =-\\frac{\\partial E_k}{\\partial b_h} \\cdot \\frac{\\partial b_h}{\\partial \\alpha_h} \\\\ &amp; =- \\sum_{j=1}^{l} \\frac{\\partial E_k}{\\partial \\beta_j} \\cdot \\frac{\\partial \\beta_j}{\\partial b_h} f^{\\prime}(\\alpha_h-\\gamma_h) \\\\ &amp; = \\sum_{j=1}^{l} w_h^j g_j f^{\\prime}(\\alpha_h-\\gamma_h) \\\\ &amp; = b_h(1-b_h)\\sum_{j=1}^{l} w_h^j g_j \\end{align}$$ 像$g_j$一样，它们是输出层和隐含层的梯度。 $$\\begin{align} \\Delta v_ih&amp;=\\eta e_h x_i \\\\ \\Delta \\gamma_h&amp;=-\\eta e_h \\end{align}$$ 以上就是标准BP算法。这个算法的目标是最小化当前的样例的误差，很可能出现上一个样例的更新被下一个样例所产生的更新给抵消了。 累积BP算法的目的在于最小数据集D的累积误差。具体计算方法就是把所有的$E_k$的偏导都加起来，在更新权值的时候也是。有空的时候我再做推导。现在要回宿舍睡觉了～ 在很多人任务里，会先使用累积BP算法先训练，当总体误差降得很低了之后，再使用标准BP算法进行训练，尤其是在训练集D特别大的时候效果特别好。 缓解BP网络的过拟合 早停：将数据分成训练集和验证集，但训练集误差降低，但是验证集误差上升时停止训练，返回具有最小验证集误差的参数。 正则化：将目标公式变为$E=\\lambda \\frac{1}{m} \\sum_{k=1}^{m} E_k +(1-\\lambda) \\sum_i w_i^2$ 5.4 全局最小与局部最小使用方法有： 以多组不同的参数值初始化多个神经网络，按标准方法训练后，取其重误差最小的作为最终参数。 使用模拟退火 使用随机梯度下降 遗传算法 这些方法大多都是启发式的，缺乏理论保障，不保证效果。 5.5 其他常见神经网络5.5.1 RBF网络RBF（Radial Basis Function)径向基函数``网络是一种单隐层前馈神经网络，它使用径向基函数作为激活函数，输出层则是对隐层神经元输出的线性组合。假定输入为d维向量x，输出为实值，则RBF网络可以表示成 $$\\begin{align} \\varphi(x) = \\sum_{i=1}^{q} w_i \\rho(x,c_i) \\end{align}$$ 其中q为隐层神经元个数，$c_i$和$w_\\i$分别是第i个隐层神经元所对应的中心和权重。 $$\\begin{align} \\rho(x,c_i)=e^{-\\beta_i||x-c_i||^2} \\end{align}$$ 训练步骤： 确定神经元中心$c_i$，通常使用随机采样、聚类 利用BP算法来确定参数$w_i$和$\\beta_i$ 5.5.2 ART网络竞争型学习是神经网络中一种常用的无监督学习策略，各个输出层神经元互相竞争，每一时刻仅有一个竞争获胜的神经元被激活。这种机制叫做胜者通吃（winner-take-all）原则。 ART(Adaptive Resonance Theory，自适应谐振理论)网络是竞争学习的重要代表。由比较层 识别层 识别阈值 重置模块构成。其中比较层负责接收输入的向量，然后将其传递给识别层,识别层的每个神经元代表一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类。 竞争最简单的方式是计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离，距离最小者胜。获胜神经元将向其他识别层神经元发送抑制激活信号。若相似度大于阈值，则当前输入样本将被归为该代表向量所属类别，同时网络的连接权将更新，使得以后在接收到相似输入样本时该模式类会计算出更大的相似度。若相似度不大于阈值，则在识别层增加一个新的神经元，其代表向量就是当前向量。 最早的ART网络只能处理布尔型输入数据，后来发展出了能处理实值输入的ART2网络，结合模糊处理的FuzzyART网络，以及可进行监督学习的ARTMAP网络。 5.5.3 SOM网络SOM(Self-Organizing Map)，自组织映射也是一种竞争学习型的无监督神经网络。 它能将高维输入数据映射到低维空间，通常是二维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。 输出神经元以矩阵的形式排布在二维空间上，同时每个神经元都有一个代表自己的权向量，同样是距离最近的神经元成为竞争获胜者。然后最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些全向量与当前输入样本的距离缩小。 5.5.4 级联相关网络这个网络多了一个学习目标，就是网络的结构。与前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。 5.5.5 Elman 网络这是一个递归神经网络（recurrent neural network），它允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号。这样的结构与信息反馈过程，使得网络在t时刻的输出状态不仅与t时刻的输入相关，还和t-1时刻的网络状态相关，从而能处理与时间有关的动态变化。 网络的训练需要通过推广的BP算法进行。 5.5.6 Boltzmann机能量最小化时网络达到理想状态。它也是一种递归神经网络，其神经元分为两层显层和隐层。显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达。并且神经元都是布尔型的。 令向量$\\bf s$是一个n维的0、1向量，表示n个神经元的状态，$w_ij$ 表示神经元i与j之间的连接权，$\\theta_i$表示神经元i的阈值。状态向量$\\bf s$的Boltzmann机的能量定义为 $$\\begin{align} E(s)=-\\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} w_{ij}s_i s_j- \\sum_{i=1}^{n} \\theta_i s_i \\end{align}$$ 其出现的概率则是有下面的式子决定 $$\\begin{align} P(s)=\\frac{e^{-E(s)}}{\\sum_t e^{-E(t)}} \\end{align}$$","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"Netural Network","slug":"Netural-Network","permalink":"http://yezhejack.github.io/tags/Netural-Network/"}]},{"title":"普通linux用户如何安装程序","slug":"普通linux用户如何安装程序","date":"2016-05-26T08:24:00.000Z","updated":"2016-07-21T07:10:42.000Z","comments":true,"path":"2016/05/26/普通linux用户如何安装程序/","link":"","permalink":"http://yezhejack.github.io/2016/05/26/普通linux用户如何安装程序/","excerpt":"","keywords":null,"text":"安装screen因为最早是使用screen的，所以想要一个screen来代替tmux。 12wget http://ftp.gnu.org/gnu/screen/screen-4.3.1.tar.gztar -xvf screen-4.3.1.tar.gz 运行 1./configure --prefix=$HOME 之后报错了，大概是ncurses找不到。于是我们需要先安装一下ncurses。 下面的安装步骤参考了这个网址里的东西 https://davidgao.github.io/LFSCN/chapter06/ncurses.html 123456wget http://ftp.gnu.org/gnu/ncurses/ncurses-5.9.tar.gztar -xvf ncurses-5.9.tar.gzcd ncurses-5.9./configure --prefix=/home/xxx/makemake install 这个会把它安装到/home/xxx/bin和/home/xxx/lib中，替代之前的安装到/usr/local中，其中各种内容会被放到对应的这个路径下的文件夹中 这时候回到我们的screen目录，我们除了将其安装程序的位置重定向之外，我们还需要额外告诉configure程序我们的额外的lib位置，因为在当前情况下我们的ncurses会有些库安装到了/home/xxx/lib中，这些库是当前screen需要的，因此安装命令变为 123./configure --prefix=/home/xxx/ LDFLAGS=\"-L/home/xxx/lib\"makemake install 默认情况下当前用户目录下的bin也会在$PATH中，如果没有的话就需要google一下怎么添加了。 这时候完成了 安装java因为我需要一个1.8版本的java，因此我需要在我的路径下能够用1.8版本的java。我们去下载一个jdk for linxu-64bit，然后解压它，放到/home/xxx/java中，然后在.bashrc的最后加上， 1234JAVA_HOME=/home/xxx/java/jdk1.8.0_73CLASSPATH=.:$JAVA_HOME/lib.tools.jarPATH=$JAVA_HOME/bin:$HOME/bin:$PATHexport PATH JAVA_HOME CLASSPATH 每个路径用:隔开，然后搜索的顺序也是按照这个顺序的（有待证实）因为我把PATH那一行中讲$PATH放到第一个之后，一直是使用全局的jdk，我调换一下位置之后就可以了。大概是优先在前面的路径中搜索相应的东西，没有的话再逐级往后找。 Virtualenv这个适合与python，可以自己单独地安装想要的package apt apt-cache search package 搜索包 apt-cache show package 获取包的相关信息，如说明、大小、版本等 sudo apt-get install package 安装包 sudo apt-get install package - - reinstall 重新安装包 sudo apt-get -f install 修复安装”-f = ——fix-missing” sudo apt-get remove package 删除包 sudo apt-get remove package - - purge 删除包，包括删除配置文件等 sudo apt-get update 更新源 sudo apt-get upgrade 更新已安装的包 sudo apt-get dist-upgrade 升级系统 sudo apt-get dselect-upgrade 使用 dselect 升级 apt-cache depends package 了解使用依赖 apt-cache rdepends package 是查看该包被哪些包依赖 sudo apt-get build-dep package 安装相关的编译环境 apt-get source package 下载该包的源代码 sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包 sudo apt-get check 检查是否有损坏的依赖","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yezhejack.github.io/tags/服务器/"}]},{"title":"词性标注","slug":"词性标注","date":"2016-05-25T14:16:00.000Z","updated":"2016-05-25T15:21:39.000Z","comments":true,"path":"2016/05/25/词性标注/","link":"","permalink":"http://yezhejack.github.io/2016/05/25/词性标注/","excerpt":"","keywords":null,"text":"词性标注10.1标记中的信息源 观察感兴趣词的邻近上下文的其它词的词性 利用词本身提供的信息，有人做了一个词性标注起dumb，这个标注器只是将所有词最常用的词性标注给这个词，就取得了90%的准确率。 因此词之间用法及其不平均，因此用统计的方法会更甚一筹。 10.2马尔可夫模型标注器10.2.1概率模型马尔可夫链的两个特性 有限视野（limited horizon）$P(X_{i+1}=t^j|X_1,...X_i)=P(X_{i+1}=t^j|X_i)$ 时间不变形$P(X_{i+1}=t^j|X_1,...X_i)=P(X_{2}=t^j|X_1)$ 下表指示标注预料库和句子中特殊位置的词和词性，用上标表示词典中的词和标注集中的词性类别。 有限视野的式子可以简化为 $P(t_{i+1}|t_{1,i})=P(t_{i+1}|t_i)$ 标记$t^k$跟随$t^j$的最大似然估计来自于不同的标记跟随某个特定标记的相对频率估计。 $P(t_{i+1}|t_i)＝\\frac{C(t^j,t^k)}{C(t^j)}$ 这个问题应用到马尔可夫里，对应的状态就是词的标注，而每次离开一个状态发射出的词就是我们的观察序列。 发射概率： $P(O_n=k|X_n=s_i,X_{n+1}=s_j)＝b_{ijk}$ 可以通过最大似然估计来直接估计一个词被一个特定的状态（标记）发射出来的概率： $P(w^l|t^j)＝\\frac{C(w^l,t^j}{C(t^j)}$ 我们最终要解决这个词性标注问题的话，我们所有求解的是下面这样的式子： $$\\arg\\max_{t_{1,n}}P(t_{1,n}|w_{1,n})=\\arg\\max_{t_{1,n}}\\frac{P(w_{1,n}|t_{1,n})P(t_{1,n})}{P(w_{1,n})}\\\\ =\\arg\\max_{t_{1,n}}P(w_{1,n}|t_{1,n})P(t_{1,n})$$ 这个式子在这里还是可以继续化解下去的，只需要再做两个假设，首先是词语之间是独立的，这样式子就变成了 $P(w_{1,n}|t_{1,n})=\\prod_{i=1}^n P(w_i|t_{1,n}) P(t_n|t_{1,n-1}) P(t_{n-1}|t_{1,n-2})...P(t_2|t_1)$ 然后在假设一下每个词的出现只依赖于自己本身的标注，那么整个式子又变为了这样 $$P(w_{1,n}|t_{1,n})=\\prod_{i=1}^n P(w_i|t_{i}) P(t_n|t_{n-1}) P(t_{n-1}|t_{1,n-2})...P(t_2|t_1)\\\\ =\\prod[P(w_i|t_i)P(t_i|t_{i-1})]$$ 10.2.2 Viterbi算法至此，可能已经一脸懵逼了，但是实际上我们已经将问题化解为了马尔可夫问题，我们可以放心地用马尔可夫链来解这个问题了。我们有了转移概率和发射概率了分别是$P(t_{i}|t_{i-1})$和$P(w_{i}|t_{i})$。然后呢，这个是一个给了观测序列，叫求状态的问题，因此用动态规划对应的Viterbi算法。在马尔可夫中有讲到。 10.2.3 算法的变形未登录词 在实践中不同的标注器在不同语料库上的不同准确率主要是由为登录词的比例决定的，智能化的标注器就需要能够对未登录词的词性进行一定的猜测。 eischedel在1993年的论文中基于三种信息估计了词语生成概率： 一个标注可以生成一个未登录词的概率有多大 生成大写词或者小写词的概率有多大 生成连字符或者特殊后缀的可能性 $P(W^l|t^j)=\\frac{1}{Z} P(unknown word|t^j) P(capitalized|t^j) P(endings or hyph|t^j)$ 三元语法标注器 之前使用的基本都是二元语法，就是只看当前词的前一个词，而三元语法会保留前面两个词的信息，保留了更多的信息。 插值和可变记忆 三元标注器会存在数据稀疏的问题。为了解决这个问题，可以采用一元、二元和三元的概率的线性插值。 $P(t_i|t_{1,i-1})=\\lambda_1 P_1(t_i) + \\lambda_2 P_2(t_i|t_{i-1})+\\lambda_3 P_3(t_i|t_{i-1},t_{i-2})$ 这种线性插值方法将在第六章中提及，怎样使用HMM来估计参数$\\lambda_i$ 已经在第九章中讲过。 还有可变记忆马尔可夫模型（Variable Memory Markov Model,VMMM）。用混合长度的状态代替了二元或者三元语法标注器中的固定长度状态，一个VMMM标注器可以从一个记忆了前两个标记（对应三元语法模型）的状态转移到一个记忆了前三个标记（对应四元语法模型）的状态，再转移到一个没有记忆（对应一元语法模型）的状态。 平滑线性插值是平滑估计的一种方法。例如Charniak(1993)使用了类似加1法的一种思想。 $P(t^j|t^{j-1})=(1-\\epsilon)\\frac{C(t^{j-1},t^j)}{C(t^{j-1})} +\\epsilon$ 可逆性一个从左到右译码（标注）的马尔可夫模型。实际上，从右到左译码是等同的。 $P(t_{1,n})=P(t_1)P(t_{1,2}|t_1)P(t_{2,3}|t_2) ... P(t_{n-1,n}|t_{n-1})=\\frac{P(t_1)P(t_{1,2})P(t_{2,3})...P(t_{n-1,n})}{P(t_1)P(t_2)...P(t_{n-1})}=P(t_n)P(t_{n-1,n}|t_n)...P(t_{2,3}|t_3)P(t_{1,2}|t_2)$ 10.3 隐马尔可夫标注器在我们有很大的标注语料库的时候，马尔可夫模型标注器可以工作得很好，但是这个情况不常见，我们会希望标注一个特定领域内的文本，这个领域内的词语生成概率与可获得的训练文本是不一样的。 10.3.1 隐马尔可夫模型在词性标注中的应用就算没有训练数据，也可以使用HMM来学习标记序列的规则。第九章中介绍的HMM包含如下的元素： 一个状态集 一个输出字母表 初始状态概率 状态转移概率 符号发射概率 有两种方法可以来处理初始化HMM的所有参数，一种是基于每个词语的统计，而另一种是基于每个等价类的统计，将词语聚集到词语等价类中，让同一类的词语允许同样的标注。我们用$b_{j.l}$来表示词语（或词类）l由标记j发射的概率。 Jelinek的方法 $b_{j.l}=\\frac{b^{*}_{j.l} C(w^l)}{\\sum_{w^m} b^{*}_{j.m} C(w^m)}$ $b^{*}_{j.l}=0 如果t^j不是w^l所允许的词性$ $b^{*}_{j.l}=\\frac{1}{T(w^l)} 其它$ Kupiec的方法 这个和前面的Jelinke的方法差不多，只是不针对每个词了，而是针对等价类，但是如果有一个很完美的数据库的话，这个方法就散失优势了。 10.3.2 隐马尔可夫模型训练中的初始化的作用为了防止训练过度，可以在训练集上留出一个验证集，每次迭代后都测试一下，在性能下降的时候就停止迭代。 10.4 基于转换的学习我们需要一个已经标注好的语料库和一个词典作为输入数据。首先用最常用的标记来标注训练语料库中的每个词，这就是我们需要词典的原因。接下来学习算法构建了一个转换的排序表，它把初始的标注转化为接近正确的标注。通过再次初始化来选择每个词最常用的标记，再应用转换，这个排序表就可以用来标注新的文本。 10.4.1 转换一个转换包括两个部分，一个是触发环境，另一个是重写规则。大概的意思就是在特定的位置上出现特殊的标注的时候，这个标注需要进行转换，触发重写规则。 10.4.2 学习算法12345678C0:=corpus with each word tagged with its most frequent tagfor k:=0 step 1 do v:=the transformation ui that minimizes E(ui(Ck)) if (E(Ck))-E(v(Ck)))&lt;e then break fi C(k+1)=v(Ck) T(k+1)=vendOutput sequence:T1...Tk 最初我们使用最常见的标记标注每个词。在每次迭代中，我们选择最可能减少错误率的转换，通过标注过的语料库$C_{k}$中的被错误标注的词语的数目来衡量错误率$E(C_k)$。 如何应用转换也有两种方式，一种是具有立即效果的，另一种是具有延迟效果的。如果是延迟转换的话A-&gt;B会将AAAA转换为ABBB。而立即转换的话则会变为ABAB。 这个标注模型的一个应用Brill(1995b)。在HMM标注中，非监督学习唯一可以获得的信息是每个词有哪些标记是允许的，我们可以利用很多词只有一种词性标记这个事实，并把它作为选择转换的积分计分函数。而且文章中展示的问题没有训练过度的问题。这个文章中使用的无监督的学习，什么是无监督的学习（unsupervised learning）呢，就是看输入的数据是没有标签的，如果有，就是有监督的学习。 会有一个转换模版，其中有context，一个待转换tags集合，一个转换目标tag，所以可见这个模版是可穷举的。然后我们假设有一个Score，先不管这个Score是怎么来了，总之每个转换（transition）都可以得出一个Score，然后选一个Score最大的，作为这个迭代产出的转换。 为了得到这个Score的计分标准比较有趣，因为如果是有监督的学习，那么可以看错误个数，但是这个方法确实无监督的。每次都是以当前已有的转换作为标准。刚开始的时候每个词都是被标注上它所有的可能词性（文中就是tags）。公式就不列举了，公式大概的意思就是找到一个好的能够消除词性标注歧义的转换是 一个通过测量在同一个context和同一个单词中无歧义地出现的一个tag的可能性大于其他tag的tag，最后的结果也不一定是完全消歧的，一个单词仍然可能含有多个可能的tag。 $freq(Y)/freq(Z)*incontext(Z,C)$这个公式中freq(Y)是在语料库中，tag Y无歧义地出现的次数，同理freq(Z)是tag Z在语料库中无歧义出现的次数,而incontext(Z,C)就是白表示在C的条件下一个单词被无歧义地被标注为Z的个数。而R是一个能让这个式子最大化的一个Z，然后Score就是等于 $incontext(Y,C)-freq(Y)/freq(R)*incontext(R,C)$公式的主体是incontext(Y,C)和incontext(R,C)，而另外的freq(Y)/freq(R)则是用于协调相对概率的。 其中有提到一种监督学习和非监督学习结合的HMM词性标注器，就是先通过监督学习，从corpus中学习到HMM的初始参数，然后再通过Baum－Welch算法在一个未标注的corpus中调整参数。 10.4.3 与其他模型的关系决策树有点类似基于转换的方式，但是它很容易特化，在以最小化错误率为目标的情况下它很容易在训练集上获得100%的正确率，但迁移到新的数据集上的时候就会显得性能很差。 10.6 标注准确率和标注器的应用10.6.1 标注准确率看论文的时候，经常看到说某某标注器提高了一个百分点或者两个百分点的准确率，通常会被窝嗤之以鼻，认为在实际应用中，这么一丁点的差别不会影响很大。但是例如一个97%准确率的标注器有63%的可能性讲一个有15个词的句子标注对，而另一个准确率达到98%的标注器则有74%的可能性将一个有15个词的句子完全标注对。因此一个百分点的提高也会对应用产生挺大的影响。","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"词性标注","slug":"词性标注","permalink":"http://yezhejack.github.io/tags/词性标注/"},{"name":"统计自然语言处理基础","slug":"统计自然语言处理基础","permalink":"http://yezhejack.github.io/tags/统计自然语言处理基础/"}]},{"title":"论文笔记：A Practical Part-of-Speech Tagger","slug":"论文笔记：A Practical Part-of-Speech Tagger","date":"2016-05-24T14:16:00.000Z","updated":"2016-05-29T08:47:49.000Z","comments":true,"path":"2016/05/24/论文笔记：A Practical Part-of-Speech Tagger/","link":"","permalink":"http://yezhejack.github.io/2016/05/24/论文笔记：A Practical Part-of-Speech Tagger/","excerpt":"","keywords":null,"text":"摘要实现了基于隐马尔可夫模型的词性标注器。这个方法只用很少的资源就可以实现鲁棒的准确的词性标注。只需要一个词表和未标注的文本。准确率超过96%。 必要条件自动化的文本标注是在更大的语料库中发现语言结果的重要的第一步。词性标注为更高层次的分析提供基础。例如识别名词和其他文本中的模式。 一个标注器得具备的几个特性： Robust鲁棒性 Efficient高效性 Accurate 准确性 Tunable 可调性，可以利用先验知识来解决系统性错误。 Reusable 可服用性 方法2.1 背景已有的几种词性标注的方法： rule-based 基于规则的 statistical methods 基于统计的 对于参数估计也有两种方法，一种需要标注好的语料库；而另一种则是利用前向－后向算法，这个不需要标注好的语料库。 2.2 论文中的方法 使用HMM可以允许在选择训练语料库上有更大的灵活性。 3 隐马尔可夫模型应用HMM有两个任务，估计参数和先验概率，在训练集合上。计算隐藏状态的转移序列。 数值稳定性因为前向后向算中使用到的乘积的结果是0到1之间的数值，很容易下溢，所以需要调整放大一下。首先是前向概率，重新计算一遍，分子是当前的前向概率，分母是当前时刻的所有前向概率的和。同样的处理过程同样应用在后向概率上。B的稀疏性可以减少一下一些运算，可以先检测对应的位置上是否有0，有的话就不用计算了。 训练集的处理方式我看这篇论文的主要目的在于知道隐马尔可夫对训练集的处理方式。如果是显马尔可夫的话，只要用最大似然的方式统计A、B以及Pi就可以了，但是如果是隐马尔可夫的话，我们需要一个序列来作为训练集。正常情况下就是把整个文本当作一个序列，作为估计，而不是以句子为单位。但是这篇文章中为了优化，将其分为多个长度相同的部分训练参数，最后将参数做平均。如果是按照每句话划分的话，最后合并的时候因为matrix的size不同，会导致无法平均。 下载地址A Practical Part-of-Speech Tagger.pdf","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"词性标注","slug":"词性标注","permalink":"http://yezhejack.github.io/tags/词性标注/"}]},{"title":"NAACL-2013-Socher-Manning-DeepLearning","slug":"NAACL-2013-Socher-Manning-DeepLearning","date":"2016-05-24T14:16:00.000Z","updated":"2016-05-29T08:44:48.000Z","comments":true,"path":"2016/05/24/NAACL-2013-Socher-Manning-DeepLearning/","link":"","permalink":"http://yezhejack.github.io/2016/05/24/NAACL-2013-Socher-Manning-DeepLearning/","excerpt":"","keywords":null,"text":"Introduction本来是在看一些关于NLP的一本老教材，但是鉴于现在组里RNN、CNN满天飞，忍不住先来窥探一下Deep Learning在NLP一些传统问题上有什么魔法。 The neural word embedding approach的优势相比于LSA方法，neural word embeddings 可以变得更有意义，通过对一个或多个任务增加监督。 无监督的词向量学习主要思想：一个词和它的上下文环境是一个学习正例；一个随机的词和前面那个一个样的上下文环境则给出了一个学习的反例。例如一个正例是cat chills on a mat，一个反例是cat chills Jeju a mat。 将其形式化：score(cat chills on a mat)&gt;score(cat chills Jeju a mat)。 利用神经网络 将每个词和一个n维向量联系在一起 目标是让正例的score比反例的score高。 s=score(cat chills on a mat)sc=score(cat cills Jeju a mat)minimize J=max(0,1-s+sc)","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"词性标注","slug":"词性标注","permalink":"http://yezhejack.github.io/tags/词性标注/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yezhejack.github.io/tags/Deep-Learning/"}]},{"title":"spawn-fcgi源码阅读","slug":"spawn-fcgi源码阅读","date":"2016-05-18T23:33:00.000Z","updated":"2016-05-26T05:48:52.000Z","comments":true,"path":"2016/05/19/spawn-fcgi源码阅读/","link":"","permalink":"http://yezhejack.github.io/2016/05/19/spawn-fcgi源码阅读/","excerpt":"","keywords":null,"text":"spawn-fcgi源码阅读收获可以解除到socket编程，在unix系统下的一些特性，比如一切皆文件。连socket也是一个文件描述符，这也是为什么在提升服务器并发性的时候需要增加文件描述符的数量，因为有些系统的文件描述符的上限只有1024个，大大限制了可以接收的请求数量。而且其实我的本意是要看一下并发模型的，结果发现这个spawn-fcgi根本没有实现任何的并发代码，感觉只是用了内核自带的并发模型。 参数解析部分 argc记录了参数的数量 argv是一个纪录参数的数据 optind是指向当前的参数指针，初始值为1 getopt会让optind不断下移，当没有更多的参数的时候返回getopt 返回－1 getopt的第三个参数是optstring，如果有冒号，则说明这个选项需要一个参数 每次都会把参数的指针放到optarg中 strtol 用于将一个字符串转换为对应基数的长整型，它会先忽略optarg的前面的尽量多的空格，然后遇到一个非空格字符后，就开始尽可能地转换字符 返回的时候如果endptr不为空的话，会让它指向翻译后的第一个字符。猜测：如果完全翻译完，是会返回NULL的，这样才可以看输入是否合法 socket的类型socket有两种，一种是绑定端口的，一种是绑定文件的(unixsocket)，其对应的协议族也是不一样的。 open需要打开文件来表示运行的进程。这里还涉及了很多unix类系统的文件操作。 unix权限保护运行程序的用户和程序拥有者的权限关系，同时还有SUID和GUID这两个可以让程序拥有者把权限“借”给程序的运行者，例如/etc/passwd就是这样，虽然非root用户无法对其进行直接修改，但是却可以通过执行对应的验证程序，获得root权限从而读取/etc/passwd的信息。 chroot 一种沙盒机制这个可以将程序运行的作用范围控制在一定的距离内。 fork()这个可以返回子进程的进程号，同时子进程拥有父进程的所有上下文，也就是让程序运行到fork()前的状态，因此可以用child来区分当前进程是子进程还是父进程。 文件描述符文件描述符的前三个0,1,2总是stdin stdout 和stderr。大量的应用程序都依赖这个特性，虽然这个好像并不是标准。 比sleep更精确的计时器在unix中sleep的精确度为1s，而select(0,NULL,NULL,NULL,&amp;val)是一个更精确的计时器，可以以微秒为单位。 源码及注释下载地址spawn-fcgi.c","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"socket","slug":"socket","permalink":"http://yezhejack.github.io/tags/socket/"},{"name":"linux","slug":"linux","permalink":"http://yezhejack.github.io/tags/linux/"},{"name":"unix","slug":"unix","permalink":"http://yezhejack.github.io/tags/unix/"}]},{"title":"socket编程的一些问题","slug":"socket编程的一些问题","date":"2016-05-18T23:33:00.000Z","updated":"2016-05-26T08:24:28.000Z","comments":true,"path":"2016/05/19/socket编程的一些问题/","link":"","permalink":"http://yezhejack.github.io/2016/05/19/socket编程的一些问题/","excerpt":"","keywords":null,"text":"多个进程监听一个socket对于监听一个socket来说，多个进程同时在accept处阻塞，当有一个连接进入，多个进程同时被唤醒，但之间只有一个进程能成功accept，而不会同时有多个进程能拿到该连接对象，操作系统保证了进程操作这个连接的安全性。 扩展：上述过程，多个进程同时被唤醒，去抢占accept到的资源，这个现象叫“惊群”，而根据网上资料，Linux 内核2.6以下，accept响应时只有一个进程accept成功，其他都失败，重新阻塞，也就是说所有监听进程同时被内核调度唤醒，这当然会耗费一定的系统资源。 而2.6以上，则已经不存在惊群现象了，但是由于开发者开发程序时使用了如epoll等异步通知技术，仍然会造成惊群，如有需要更高性能要求，或许参考nginx的实现方案，这里就不详述了。 作者：云帆技术博客 这个方面可以从socket的accept函数的源码中得到解答，每个socket维护了一个deque来存储请求，可见是个FIFO的请求结构。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"socket","slug":"socket","permalink":"http://yezhejack.github.io/tags/socket/"},{"name":"linux","slug":"linux","permalink":"http://yezhejack.github.io/tags/linux/"},{"name":"unix","slug":"unix","permalink":"http://yezhejack.github.io/tags/unix/"}]},{"title":"flask学习笔记","slug":"Flask学习笔记","date":"2016-05-16T12:56:00.000Z","updated":"2016-05-18T13:11:17.000Z","comments":true,"path":"2016/05/16/Flask学习笔记/","link":"","permalink":"http://yezhejack.github.io/2016/05/16/Flask学习笔记/","excerpt":"","keywords":null,"text":"Flask安装flask依赖两个外部库，一个是Werkzeug，一个提供WSGI支持，还有一个是Jinja2负责解析模版。 virtualenv它提供了分离运行环境的功能。 123makdir my projectcd myprojectvirtualenv venv 1. venv/bin/activate 最简单的应用1234from flask import Flask app = Flask(__name__) @app.route( / )def hello_world(): return Hello World! if __name__ == __main__ : app.run() 这个默认情况下是在debug模式下运行的，它只监听来自127.0.0.1的请求。想要关闭debug消息的话需要修改为下面的代码。 1234from flask import Flask app = Flask(__name__) @app.route( / )def hello_world(): return Hello World! if __name__ == __main__ : app.run(host='0.0.0.0') flask还提供了debug模式，就是不需要每次改完代码再重启服务。只要代码有修改那么只需要把代码改为 1234from flask import Flask app = Flask(__name__) @app.route( / )def hello_world(): return Hello World! if __name__ == __main__ : app.run(debug=True) 或者 12345from flask import Flask app = Flask(__name__) @app.route( / )def hello_world(): return Hello World! if __name__ == __main__ : app.debug=True app.run() 在多进程的环境下似乎会有问题。 路由在函数前加一个修饰，可以指定URL到这个函数中 1234567@app.route('/')def index(): return 'Index Page'@app.route('/hello')def hello(): return 'Hello World' 规则变量类似C＋＋中的重载，但在python中是根据变量的名字来找到对应的函数。 1234567@app.route('/user/&lt;username&gt;')def a(username): return 'hello'@app.route('/user/&lt;int:post_id&gt;')def a(post_id): return 'wolrd' 可以使用的用来分流的东西有int、float和path。 如果一个路径规则有一个/的话，当一个URL没有/的话，程序也会自动补上，但是反过来则无法匹配了。 URL生成1&gt;&gt;&gt;from flask import Flask, url_for &gt;&gt;&gt; app = Flask(__name__) &gt;&gt;&gt; @app.route( / ) ... def index(): pass ... &gt;&gt;&gt; @app.route( /login ) ... def login(): pass ... &gt;&gt;&gt; @app.route( /user/&lt;username&gt; ) ... def profile(username): pass ... &gt;&gt;&gt; with app.test_request_context(): ... print url_for( index ) ... print url_for( login ) ... print url_for( login , next= / ) ... print url_for( profile , username= John Doe ) ... / /login /login?next=/ /user/John%20Doe 4.3.3 HTTP方法默认情况下，flask app只对GET方法有回应，如果要接受POST方法的话 1234@app.route( /login , methods=[ GET , POST ]) def login(): if request.method == POST : do_the_login() else: show_the_login_form() 4.5 套用模版回复的时候为了可以套入模版，可以使用render_template方法。 需要将模版放在文件夹/templates/中。 case 1:a module: 123/application.py/templates /hello.html case 2:a package 1234/application /__init__.py /templates /hello.html 4.6 读取请求数据flask中使用的是全局的request object，但它本身是线程安全的。 4.6.1 Context Locals此处暂时没懂。 4.7 错误可以使用模版来自定义错误界面。 8.4 其它模块的日志当有其它模块的时候，为了让它的log也能写进来，可以使用下面的代码。 12345from logging import getLoggerloggers=[app.logger,getlogger('sqlalchemy'),getLogger('otherlibrary')]for logger in loggers: logger.addhandler(mail_handler) logger.addHandler(file_handler)","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"flask","slug":"flask","permalink":"http://yezhejack.github.io/tags/flask/"},{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"},{"name":"framework","slug":"framework","permalink":"http://yezhejack.github.io/tags/framework/"}]},{"title":"Minimal Height Tree","slug":"Minimal Height Tree","date":"2016-05-10T07:51:00.000Z","updated":"2016-05-18T05:56:39.000Z","comments":true,"path":"2016/05/10/Minimal Height Tree/","link":"","permalink":"http://yezhejack.github.io/2016/05/10/Minimal Height Tree/","excerpt":"","keywords":null,"text":"Minimal Height Tree尝试了用暴力解法，无奈超时了，于是用了比较巧妙的解法。题目中提示答案的顶点数是有范围的，可以通过不断地删除度为1的点，调整每个节点的度，来求最后的答案。","raw":null,"content":null,"categories":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://yezhejack.github.io/categories/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://yezhejack.github.io/tags/Leetcode/"},{"name":"题解","slug":"题解","permalink":"http://yezhejack.github.io/tags/题解/"}]},{"title":"如何在python中使用正则表达式","slug":"正则表达式","date":"2016-05-10T07:51:00.000Z","updated":"2016-05-18T05:56:28.000Z","comments":true,"path":"2016/05/10/正则表达式/","link":"","permalink":"http://yezhejack.github.io/2016/05/10/正则表达式/","excerpt":"","keywords":null,"text":".匹配除了换行符以外的任意字符。 *表示前面的内容可以连续重复任意次。 .*就表示匹配前面任意个除换行符外的字符组成的字符串。 简介略过。讲讲我的心路历程吧 正则表达式这个我真的是拖了很久才开始接触的东西，现在终于避不过去了，现在有个要探测字符串中是否含有QQ表情和emoji表情的任务。目标语言是python 简单模式2.1 匹配字符必须要掌握的是元符号metacharacter。这里有一个完整的元符号列表 . ^ $ * + ? { } [ ] \\ | ( ) 首先是[和]这两个符号。它们用来表示一组符号，你希望用这组符号之一来匹配，这里面也可以表示一个范围，使用-来连接两个符号，来表示范围。例如[abc]可以匹配a，b或c之一，这个相当于[a-c]。 其他元符号在字符组中不再是元字符的概念。例如[amk$]会匹配下面的任意一个字符a，k，m或$。 如果在字符组的第一个是一个^的话表示这个字符组会匹配不在这个字符组中的任何一个，如果是在外面的话就只是简单地匹配^这个字符。 \\是一个转义符，加在元字符前会让这个元字符不在是元字符，而是简单地匹配它本身。类似python中的字符串。同时它也和一些符号也可以组成一些特殊的符号，来表示一些预先定义好的字符组。 \\d相当于[0-9] \\D相当于[^0-9] \\s相当于[\\t\\n\\r\\f\\v]，匹配所有空白字符 \\S相当于[^\\t\\n\\r\\f\\v]，匹配所有非空白字符 \\w相当于[a-zA-Z0-9_] \\W相当于[^a-zA-Z0-9_] 这符号可以放在字符组中，例如[\\s,.]可以匹配任何的非空白字符以及,和.。 还有一个元字符.表示匹配除了回车符号的字符。 2.2 重复的东西元字符*并不匹配真正的符号*，相反的，它可以匹配让前面部分重复0至任意次数的字符串。遇到带元符号*的表达式，它会尽可能长地匹配子串。它会先尽量长地去先匹配，然后根据后面的字符来不断缩短自己的长度。 另一个可以重复的元字符是+，表示匹配一次或者多次。差别在于这个元字符至少得一次。 元字符?表示匹配一次或者零次。 最复杂的表示重复的元字符是{m,n}，m和n是两个整数，$m \\leq n$。这个表示对应的部分最少重复m次，最多重复n次。如果m缺了，会自动补上0，如果n缺了，会认为可以最多重复无限多次。当然说无限多次，依然是由机器、软件等限制的。 3 使用正则表达式首先要把正则表达式编译成一个object，然后在去match他们。 3.1 编译正则表达式p=re.compile(&#39;ab*&#39;,re.IGNORECASE)可以忽略大小写。 3.2 backslash灾难这里会产生很多的麻烦，而且让结果很难理解，因此可以使用字符的前缀r处理字符串，例如r&quot;\\n&quot;不再是一个回车了，而是两个字符\\和n。 3.3 匹配 match()如果没匹配，则返回None search()如果没匹配，则返回None findall()找到所有的匹配子串，然后返回一个list finditer()找到所有的匹配子串，然后返回一个迭代器 我们可以从match object里面通过下面四个函数获得匹配的信息 group()返回匹配的字符串 start()``end()返回开始和结束的位置 span()返回一个元组表示(start,end) 3.4 模块级别的函数可以使用不创建re的object的调用方法，例如re.match(r&#39;From\\s+&#39;,&#39;Fromage amk&#39;)，这个方法会在cache中创建object。之后使用相同的RE的话速度会快。 3.5 解释标志 DOTALL和S会让.匹配任何字符，包括换行符。 IGNORECASE和I会忽略大小写来进行匹配。 LOCALE和L这个会根据你的系统是哪个国家的，改变对应的字符集例如\\w的字符范围 MULTITLINE和M这个flag会影响到^和$等符号 UNICODE和U让\\w \\W \\b \\B \\d \\D \\s \\S依靠Unicode，这个还有待考察 VERBOSE和X这个可以在里面插入用#的注释 更多的模式更多的元符号 \\b是匹配一个词的边界 |是一个表示或的符号，但是它的优先级很低，这样可以让它的结果更合理，例如Crow|Servo表示的是匹配Crow和Servo中的其中一个，而不是w货S中的一个。 ^表示匹配字符串的开端，如果有MULTILINE的标志的话，它也会匹配每个换行，如果只是想匹配在句子首部的单词From的话，可以使用的正则表达式是^From。 $匹配的是句尾、行尾或者换行符号的后面的位置 \\A在没有MULTILINE的情况下和^一样，但是在有MULTILINE的情况下也只匹配字符串首部 \\Z无论什么情况下也都匹配字符串的尾部 \\b前面已经介绍过了，但是这里要抢到一个很严重的冲突，如果没有在正则表达式的字符串前加上r的话，python会把\\b处理成空格，这样就无法正常匹配了 \\B则是匹配不是词的边界 4.2 Grouping可以用(和)来讲许多字符当作一个整体，类似数学计算中的概念。","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://yezhejack.github.io/tags/正则表达式/"}]},{"title":"HTTP学习以及push机制","slug":"HTTP学习以及push机制","date":"2016-05-07T13:19:00.000Z","updated":"2016-05-07T13:40:28.000Z","comments":true,"path":"2016/05/07/HTTP学习以及push机制/","link":"","permalink":"http://yezhejack.github.io/2016/05/07/HTTP学习以及push机制/","excerpt":"","keywords":null,"text":"什么是长连接当客户端用TCP/IP协议从服务器上获取数据的时候，都需要一个连通客户端和服务器的连接，连接通过三次握手建立，通过四次握手释放。如果每次获取数据都创建一个独占的连接，并在数据传输完毕后释放，这种连接叫做短连接。而一个能够供多个请求多次传输数据，并在数据传输后保活一段时间的连接，我们称之为长连接。（转载自http://www.chanpin100.com/archives/58040）。 push机制利用的就是长连接，因为ios只要和官方的推送服务器发送心跳，因此很省电，但是国内的android无法使用google的推送服务器，因此各个app得自己建立推送管道，同时这些管道还不能被各种管家杀死。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://yezhejack.github.io/tags/HTTP/"},{"name":"push","slug":"push","permalink":"http://yezhejack.github.io/tags/push/"},{"name":"长连接","slug":"长连接","permalink":"http://yezhejack.github.io/tags/长连接/"},{"name":"短连接","slug":"短连接","permalink":"http://yezhejack.github.io/tags/短连接/"}]},{"title":"马尔可夫模型","slug":"统计自然语言处理基础-第九章-马尔可夫模型","date":"2016-05-05T09:09:00.000Z","updated":"2016-05-08T03:18:36.000Z","comments":true,"path":"2016/05/05/统计自然语言处理基础-第九章-马尔可夫模型/","link":"","permalink":"http://yezhejack.github.io/2016/05/05/统计自然语言处理基础-第九章-马尔可夫模型/","excerpt":"","keywords":null,"text":"马尔可夫模型9.3 隐马尔可夫模型的三个基本问题 给出一个模型$\\mu=(A,B,\\pi)$，怎样有效地计算某个观测序列发生的概率，即$P(O|\\mu)$？ 给出观测序列$O$和模型$\\mu$，我们怎样选择一个状态序列$(X_{1},...,X_{T+1})$，以便能够最好地解释观测序列？ 给定观测序列$O$，以及通过改变模型$\\mu=(A,B,\\pi)$的参数而得到的模型空间，我们怎样才能找到一个最好地解释这个观测序列的模型。 这中间包含了三个量： 观测序列$O$ 模型$\\mu$ 状态序列$(X_{1},...,X_{T+1})$ 第一个是马尔可夫模型的正向用途，第二个是求出隐藏状态，第三个则是学习过程，即通过现象去学习一个模型。 9.3.1计算观测序列的概率每个状态到达观测序列$O$都有一定的概率，我们将所有状态到达观测状体的概率相加不就可以得到在给定模型$\\mu$的情况下，观测序列$O$出现的概率。 给定一个状态序列$(X_{1},...,X_{T+1})$，然后对应的到达$O$的概率就为 $$P(O|X,\\mu)=\\Pi_{t=1}^{T}P(O_t|X_t,X_t+1,\\mu) =b_{X_{1}X_{2}o_{1}} b_{X_{2}X_{3}o_{2}}...b_{X_{T}X_{T+1}o_{T}}$$ 出现这个状态序列的概率为 $P(X|\\mu)=\\pi_{x_1}a_{X_1 X_2}a_{X_2 X_3}...a_{X_TX_{T+1}}$ 因此 $P(O,X|\\mu)=P(O|X,\\mu)P(X|\\mu)$ 最终 $P(O|\\mu)=\\sum_X P(O|X,\\mu)P(X|\\mu)$ 分析一下这个算法，虽然说这个算法非常直观，推导也是初学者级别（没错就是我），但是首先给定一个$X$我们想要算出$P(O,X|\\mu)=P(O|X,\\mu)P(X|\\mu)$就需要$T-1+T+1$次的乘法，然后$X$还有$N^{T+1}$个组合，算出每个组合就需要$(2T)N^{T+1}$次乘法，再将这些组合的结果相乘，就得到了$(2T＋1)N^{T+1}$次乘法的需求。 直觉告诉我这里面有重复计算的结果，其实整个计算过程和动态规划很像，每条边都有代价 一个格子$(S_i,t)$存储了一些信息。 前向过程 $\\alpha_i(t)=P(o_1 o_2 ... o_{t-1},X_t=i|\\mu)$ $\\alpha_i(t)$存储在格路的$(S_i,t)$中，表示在$t$时刻已状态$S_i$结束的概率。 初始化 $\\alpha_i(1)=\\pi_i,1 \\leq i \\leq N$ 推导 $\\alpha_i(t+1)=\\sum_{t=1}^{N} \\alpha_i(t) a_{ij}b_{ijo_t},1\\leq t\\leq T,1\\leq j\\leq N$ 求和 $P(O|\\mu)=\\sum_{i=1}^N\\alpha_i(T+1)$ 用前向过程来计算观测序列的概率，可以只需要$2N^2T$次乘法就可以搞定了。 后向过程这个过程是和前向相对应的，所表示的意思是从当前t时刻开始，观测到$T$这样的观测序列，并且知道t时刻的隐藏状态是$X_{t}$。在给定的模型$\\mu$的情况下，能观察到之前的序列的概率就称为后向过程。之所以要引入后向概率是为了解决三个基本问题中的第三个问题。 给出的公式如下： $\\beta _{i}(t)=P(o_{t}...o_{T},X_{t},\\mu)$ 后向过程理解起来会有点难度，特别是像我这样直观先行的动物来说，对于公式总得翻译得直白一点才能想想。这个过程也就是当某一时刻$X_t=i$的情况下，开始转换的到最后能得出$o_{t}...o_{T}$这个观测序列的概率，也就是$\\beta _{i}(t)$，这样我们可以依赖于。如果我们知道$\\beta _{i}(t＋1)$的值的话，这个就很简单了，$\\beta _{i}(t)$想要到达最后的概率是通过各个$\\beta _{i}(t＋1),1 \\leq i \\leq N$的节点到达最后的概率只喝，因此它的推导公式就很好理解了。 初始化 $\\beta _{i}(T +1)=1, 1\\leq i\\leq N$ 推导 $\\beta _{i}(t)=\\sum_{j+1}^{N}a_{ij}b_{ijo_t}\\beta _{j}(t+1),1\\leq t\\leq T 1\\leq i \\leq N$ 求和 $P(O|\\mu)=\\sum_{i=1}^{N}\\pi_i\\beta_i(1)$ 前向后向的结合我们可以让前向后向公式结合来计算一个观测序列的概率 $P(O,X_{t}=i|\\mu)=\\alpha_{i}(t)\\beta_{i}(t)$ 有了这个中间公式之后，我们就可以计算 $P(O|\\mu)=\\sum_{i=1}^{N}\\alpha_{i}(t)\\beta_{i}(t),1\\leq t \\leq T +1$ 到此为止，我们解决了第一个问题了 9.3.2确定最佳状态序列这个过程通常被称为是一个译码，被人模糊地描述为“找到能够最好地解释观测值的状态序列”。存在两种方法： 对于每一个$t,1\\leq t \\leq T+1$，我们可以找到$X_t$，使得$P(X_t|O,\\mu)$最大 但这个方式实际上是最大化了奖杯正确猜测的状态的期望数目，所以最常用的方法是Viterbi算法。 Viterbi算法 我们希望找到一个状体序列$X$: $\\arg\\max_{X} P(X|O,\\mu)$ 我们可以比较容易得到在一个模型$\\mu$下，同时得到一个观测序列$O$和状态序列$X$的概率是多少，固定观测序列后，前面的问题的解等价于下面这个问题的解。 $\\arg\\max_{X} P(X,O|\\mu)$ 这个地方我需要解释一下，这个问题是如何转移的 $P(X,O|\\mu)=P(X|O,\\mu)P(O|\\mu)$ 然后由于$P(O|\\mu)=1$，因为它是给定的，所以概率当然为1啦。因此左右两边相等，因此前面的问题等价可以成立。 为了解决这个问题，定义： $\\delta_j(t)=\\max_{X_1...X_{t-1}} P(X_1 ... X_{t-1},o_1 ... o_{t-1},X_t=j|\\mu)$ 变量$\\psi_j(t)$记录了导致这条最可能路径的入弧节点。还是用动态规划的思想来解决。 初始化 $\\delta_j(t)=\\pi_j,1 \\leq j \\leq N$ 推导 $\\delta_j(t+1)=\\max_{1 \\leq i \\leq N}\\delta_i(t)a_{ij}b_{ijo_t},1\\leq j\\leq N$ 然后存储回溯路径 $\\psi_j(t+1)=\\arg\\max_{1 \\leq i \\leq N}\\delta_i(t)a_{ij}b_{ijo_t},1\\leq j\\leq N$ 终止以及路径读出 $$\\hat{X}_{T+1}=\\arg\\max_{1 \\leq i \\leq N}\\delta_i(T+1)\\\\ \\hat{X}_t=\\psi_{\\hat{X}_{T+1}}(t+1)\\\\ P(\\hat{X})=\\max_{1 \\leq i \\leq N}\\delta_i(T+1)$$ 9.3.3隐马尔可夫的参数估计问题这个问题可以看作是求解下面这个式子。这个已经可以算是机器学习的问题，对一个式子进行最优化，这里用的最优化方法是EM算法的一个特例。因为这个问题没有一个解析解，并不像之前的两个问题一样。这个方法叫做迭代爬山算法，也叫做Baum-Welch或前向后向算法。 $\\arg \\max_{\\mu} P(O_{training}|\\mu)$ 过程 $p_t(i,j)$是在给定观测序列$O$的情况下，在$t$时刻经过某条弧的概率。$$p_t(i,j)=P(X_t=i,X_{t+1}=j|O,\\mu)\\\\ =\\frac{P(X_t=i,X_{t+1}=j,O|\\mu)}{P(O|\\mu)}\\\\ =\\frac{\\alpha_i(t) a_{ij}b_{ijo_t} |beta_j(t+1)}{\\sum_{m=1}^N\\alpha_m(t)\\beta_m(t)}\\\\ =\\frac{\\alpha_i(t) a_{ij}b_{ijo_t} |beta_j(t+1)}{\\sum_{m=1}^N \\sum_{n=1}^N \\alpha_m(t) a_{mn}b_{mno_t}\\beta_n^{t+1}}$$ 求解上面这个式子是这个问题的关键，因为更新$\\pi$，$A$和$B$都需要这个式子 计算这个的时候需要先计算出前向过程和后向过程，上面这个式子实际上可能是有误导性的，因为虽然它把这个分的这么细，但实际上都需要前向和后向过程，所以可以直接获得$P(O|\\mu)$。然后分子就更好算了，其中四个量都是已知的。有了$p_t(i,j)$之后，$a_{ij}$就是可以更新为所有从i出发到达j的弧的概率除以从i出发的概率，$\\pi_i$则是在$t=1$时刻的从$i$出发的弧的个数除以$t=1$时刻出发的所有弧的个数。$b_{ijk}$则是所有从i到j的弧中，发射出状态k的概率。 这样之后一次参数更新就完成了，我们就有了新的模型，当观察序列的出现概率没有显著增长的话，算法就可以停止了。","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"统计自然语言处理基础","slug":"统计自然语言处理基础","permalink":"http://yezhejack.github.io/tags/统计自然语言处理基础/"},{"name":"马尔科夫","slug":"马尔科夫","permalink":"http://yezhejack.github.io/tags/马尔科夫/"},{"name":"HMM","slug":"HMM","permalink":"http://yezhejack.github.io/tags/HMM/"}]},{"title":"基于hexo开源架构的GitHub博客维护","slug":"基于hexo开源架构的GitHub博客维护","date":"2016-05-01T16:00:00.000Z","updated":"2016-05-31T05:59:01.000Z","comments":true,"path":"2016/05/02/基于hexo开源架构的GitHub博客维护/","link":"","permalink":"http://yezhejack.github.io/2016/05/02/基于hexo开源架构的GitHub博客维护/","excerpt":"","keywords":null,"text":"添加博文 进入到hexo的根目录，然后在 source/_posts中建立一个新的以.md结尾的markdown文档。 文档开头需要填写yaml格式的描述，用于网站的存放 123456789title: 基于hexo开源架构的GitHub博客维护date: 2015-11-23 17:52:37tags:- 站点维护- hexo- githubcategories:- 维护description: 维护博客的工作流程 然后接下去输入编辑好的文档 打开终端输入下面的命令即可完成添加及更新网站123cd hexo根目录hexo ghexo deploy 更改主题 更改主题后整个添加博文的操作会有变化，变化的结果取决于主题的样式 我添加的一个是使用git clone把文件都放到theme/主题名的文件夹中，然后在_config.yml中更改相应属性 增加关于页面1hexo new page &lt;pagename&gt; 这里把&lt;pagename&gt;填成about就可以新建一个关于页面了。会在source/about/下生成一个index.md的文件，这个就是用来编辑这个页面的markdown文件了。 feature添加评论功能首先需要申请一个disqus的账号，然后针对你所建立的个人blog建立一个对应的站点，这里将会集合你的博客评论。然后在themes/maupassant/_config.yml中在对应的地方填上站点对应的shortname。这个shortname要注意。 最近评论功能因为对于前端开发不是很清楚，但是看了一下源码，似乎截止2016.5.2这天的maupassant是有问题存在的，其中recent_comment的地址模版似乎给错了，需要修改一下themes/maupassant/layout/_widget/recent_comments.jade文件。 修改后的样子 12345if theme.disqus .widget .widget-title i(class='fa fa-comment-o')= ' ' + __('recent_comments') script(type='text/javascript', src='http://#&#123;theme.disqus&#125;.disqus.com/recent_comments_widget.js?num_items=5&amp;num_items=5&amp;hide_mods=0&amp;hide_avatars=0&amp;avatar_size=32&amp;excerpt_length=100') 这样应该就可以了 修改网站的配置这里需要打开_config.yml。对里面的language和theme都要进行对应的修改。 swiftype 搜索功能的加入这里依然需要去相应网站去设置，主要问题在于给出的代码应该加在什么地方。新版本的maupassant里面单独有一个themes/maupassant/layout/_widget/search.jade。 12345678910if theme.swiftype .widget input.st-default-search-input(placeholder='Search' type='text') script. (function(w,d,t,u,n,s,e)&#123;w['SwiftypeObject']=n;w[n]=w[n]||function()&#123; (w[n].q=w[n].q||[]).push(arguments);&#125;;s=d.createElement(t); e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e); &#125;)(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st'); _st('install','Z-tgtsfWWX8ZNoWubjoC','2.0.0'); 当然在themes/maupassant/_config.yml中还需要填入key才行 插入图片 在source/img中存入图片，命名为avator.jpg。 在markdown中写入图片 1![头像](/img/avator.jpg) 数学公式hexo为数学公式提供了mathjax，这个按照网站介绍的来看是可以插入行内数学公式的。 1234567891011121314$$\\frac&#123;\\partial u&#125;&#123;\\partial t&#125;= h^2 \\left( \\frac&#123;\\partial^2 u&#125;&#123;\\partial x^2&#125; +\\frac&#123;\\partial^2 u&#125;&#123;\\partial y^2&#125; +\\frac&#123;\\partial^2 u&#125;&#123;\\partial z^2&#125;\\right)$$Simple inline $a = b + c$.&#123;% math %&#125;\\begin&#123;aligned&#125;\\dot&#123;x&#125; &amp; = \\sigma(y-x) \\\\\\dot&#123;y&#125; &amp; = \\rho x - y - xz \\\\\\dot&#123;z&#125; &amp; = -\\beta z + xy\\end&#123;aligned&#125;&#123;% endmath %&#125; $$\\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$ Simple inline $a = b + c$. $$\\begin{aligned} \\dot{x} &amp; = \\sigma(y-x) \\\\ \\dot{y} &amp; = \\rho x - y - xz \\\\ \\dot{z} &amp; = -\\beta z + xy \\end{aligned}$$","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"站点维护","slug":"站点维护","permalink":"http://yezhejack.github.io/tags/站点维护/"},{"name":"hexo","slug":"hexo","permalink":"http://yezhejack.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://yezhejack.github.io/tags/github/"}]},{"title":"LibSVM使用","slug":"LibSVM使用","date":"2016-04-25T15:21:02.000Z","updated":"2016-05-04T14:15:29.000Z","comments":true,"path":"2016/04/25/LibSVM使用/","link":"","permalink":"http://yezhejack.github.io/2016/04/25/LibSVM使用/","excerpt":"","keywords":null,"text":"LIBSVM的使用背景毕设需要SVM来做二元分类，于是使用了LIBSVM。这里将先阅读LIBSVM的使用方法，而后再慢慢调整我的参数。参考文档就是LIBSVM官方给出的guide。 推荐使用过程 转换数据格式 对数据进行正规化，这一步很重要 通常先考虑RBF作为模型 使用cross-validation来选择参数 然后使用选择好的参数进行训练 测试","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"LIBSVM","slug":"LIBSVM","permalink":"http://yezhejack.github.io/tags/LIBSVM/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://yezhejack.github.io/tags/machine-learning/"}]},{"title":"机器翻译","slug":"统计自然语言处理基础-第十三章-机器翻译","date":"2016-04-17T06:22:00.000Z","updated":"2016-05-07T02:57:57.000Z","comments":true,"path":"2016/04/17/统计自然语言处理基础-第十三章-机器翻译/","link":"","permalink":"http://yezhejack.github.io/2016/04/17/统计自然语言处理基础-第十三章-机器翻译/","excerpt":"","keywords":null,"text":"第十三章 机器翻译存在问题 词的歧义 词序 句法歧义 几种常见的翻译模式 直接翻译法：词对词的对齐翻译方式。从源语言的表层句子出发，将词或固定词组直接置换成目标语言的对应成分，这种方式的最大缺陷就在于语言和语言之间可能不存在一一对应关系。同时词的歧义也是一个问题。这个需要参照上下文才能确定这个词改如何翻译。词序也有问题，句法转换可以解决这个问题，将其用手工定义的规则转换成一颗树，然后在这棵树上生成目标语言。这里面也存在句法歧义的问题。 语义转换方法：将原文转换为语义表示形式，然后在这个基础上生成目标语言。但通常会导致译文生涩难懂。 中间语言转换：中间语言独立于任何语言。这样在开发多语言翻译系统的时候是非常方便的，针对每个语言只需要开发一个分析模块和生成模块。但设计这样的中间语言是一件难度非常大的事情。 文本对齐可以拿多语言国家政府的官方文件作为平行语料库。 句子对齐河段落对齐简单地说句子对齐就是将源语言中的一组句子和目标语言中的一组句子进行对应的过程。每组句子可以为空，也可以额外加入对应源语言中不存在的句子或者删除原有的句子，我们称这两组对应的句子为一个句珠(bead)。 如何判定对齐：如果出现有个别词语对齐，则不能说它们是对齐的，但是如果是有任何子句对应出现，就可以判定句子之间的对齐关系。 有可能会出现交叉对应的情况，也就是一组的第一句话和另一组的第二句话有关系。因此有必要区分对齐（alignment）和对应（correspondence）之间的差别。对齐不允许交叉。 基于长度的对齐算法这个方法的基本思想是，假设源语言和目标语言的句子长度存在比例关系，即原文中过的短句对应于目标语言中的短句，长句对应于长句。 $\\arg\\max_A P(A|S,T)==\\arg\\max_A P(A,S,T)$ 目标是找出让这个概率值最大的A，其中A为对齐方式，S代表源语言，T代表目标语言。 这就转换成一个动态规划问题了，找出最小耗费函数。 因此我们需要找到每种对齐方式的耗费函数。 加强版的可以增加一些词锚（lexical anchor）概念，即利用一些有固定译法的单词或者短语结构，删除在语料中没有充分对齐的段落。 但是当对齐不同语系的文本的时候，算法的效果并不是很令人满意。 基于信号处理技术的偏移位置对齐算法大致思想基于信号处理方法的偏移位置对齐算法没有试图对齐句子，而是在平行文本中利用位置偏移量的概念，即源文本中一定位置的文本和目标语言中一定位置的文本是大致对齐的 Church(1993)的方法利用同源词信息（e.g.不同语言中的词由于借鉴或者来源于同一种祖先语言而具有的相同特征。因为OCR识别输出文本经常以后段落分割标记、标点符号以及诸如脚注、表等文本信息。 Church首先将源语言和目标语言连接起来，构建一个点阵图。坐标(x,y)处的点表示连接文本中位置x与位置y处的文本匹配，将4-gram作为匹配的最小单位。 Fung and McKeown(1994)适用范围 无需考虑句子的边界 双语文本只是局部对齐，即源语言和目标语言文本之间存在很多没有对齐的段落 与具体的语言无关 做法： 先导出一个小规模的双语词典，词典提供一些对齐的基点。每个词对应一个信号，用到达向量表示，标记了词的不同出现位置之间的词数。例如一个词出现了4次，位置向量为（1，263，267，519），那么词的到达向量事（262，4，252）。 动态时间伸缩（Dynamic Time Warping）。","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"机器翻译","slug":"机器翻译","permalink":"http://yezhejack.github.io/tags/机器翻译/"},{"name":"统计自然语言处理基础","slug":"统计自然语言处理基础","permalink":"http://yezhejack.github.io/tags/统计自然语言处理基础/"}]},{"title":"NLP入门","slug":"NLP入门","date":"2016-04-17T05:37:47.000Z","updated":"2016-05-05T12:36:36.000Z","comments":true,"path":"2016/04/17/NLP入门/","link":"","permalink":"http://yezhejack.github.io/2016/04/17/NLP入门/","excerpt":"","keywords":null,"text":"入门书籍比较古老的两本 统计自然语言处理基础 自然语言处理基础 第一版 自然语言处理基础 第二版 这个是CMU的老师王威廉在微博上推荐的书籍，图侵删 前两本都极其古老，但是据说不错，在看的是统计自然语言处理基础。 论文集ACL","raw":null,"content":null,"categories":[{"name":"NLP","slug":"NLP","permalink":"http://yezhejack.github.io/categories/NLP/"}],"tags":[{"name":"Natural Language Processing","slug":"Natural-Language-Processing","permalink":"http://yezhejack.github.io/tags/Natural-Language-Processing/"},{"name":"入门计划","slug":"入门计划","permalink":"http://yezhejack.github.io/tags/入门计划/"}]},{"title":"STL学习笔记-4-序列式容器","slug":"STL学习笔记-4-序列式容器","date":"2016-04-16T13:32:58.000Z","updated":"2016-05-04T14:20:03.000Z","comments":true,"path":"2016/04/16/STL学习笔记-4-序列式容器/","link":"","permalink":"http://yezhejack.github.io/2016/04/16/STL学习笔记-4-序列式容器/","excerpt":"","keywords":null,"text":"vectorvector实际上是一个大小不定的线性空间。 vector提供的是Random Access Iterators。 如果加入新的元素时，空间不足以容纳，就会去请求更大的空间，来容纳。 12345678void push_back(const T&amp; x) &#123; if (finish != end_of_storage) &#123; construct(finish, x); ++finish; &#125; else insert_aux(end(), x); &#125; 1234567891011121314151617181920212223242526272829303132333435template &lt;class T, class Alloc&gt;void vector&lt;T, Alloc&gt;::insert_aux(iterator position, const T&amp; x) &#123; if (finish != end_of_storage) &#123; construct(finish, *(finish - 1)); ++finish; T x_copy = x; copy_backward(position, finish - 2, finish - 1); *position = x_copy; &#125; else &#123; const size_type old_size = size(); const size_type len = old_size != 0 ? 2 * old_size : 1; iterator new_start = data_allocator::allocate(len); iterator new_finish = new_start; __STL_TRY &#123; new_finish = uninitialized_copy(start, position, new_start); construct(new_finish, x); ++new_finish; new_finish = uninitialized_copy(position, finish, new_finish); &#125;# ifdef __STL_USE_EXCEPTIONS catch(...) &#123; destroy(new_start, new_finish); data_allocator::deallocate(new_start, len); throw; &#125;# endif /* __STL_USE_EXCEPTIONS */ destroy(begin(), end()); deallocate(); start = new_start; finish = new_finish; end_of_storage = new_start + len; &#125;&#125; listlist是一种链表。 list.sort()STL为list设计的sort算法速度及其高，但是占用内存还挺多的。因为它建立65个空的list来作为中间介质。 1234567891011121314151617181920template &lt;class T, class Alloc&gt;void list&lt;T, Alloc&gt;::sort() &#123; if (node-&gt;next == node || link_type(node-&gt;next)-&gt;next == node) return; list&lt;T, Alloc&gt; carry; list&lt;T, Alloc&gt; counter[64]; int fill = 0; while (!empty()) &#123; carry.splice(carry.begin(), *this, begin()); int i = 0; while(i &lt; fill &amp;&amp; !counter[i].empty()) &#123; counter[i].merge(carry); carry.swap(counter[i++]); &#125; carry.swap(counter[i]); if (i == fill) ++fill; &#125; for (int i = 1; i &lt; fill; ++i) counter[i].merge(counter[i-1]); swap(counter[fill-1]);&#125; 对应的counter[i]在使用的时候会存储2^i个元素，否则就存储0个元素。大量使用了merge，速度极快。原书中作者注释有误，此处应该是归并排序而非quick sort（快排）。 dequedeque从逻辑上来看，是连续空间的，同vector不同的在于它可以在连续空间的两端进行操作，而且deque在空间需要增长的时候不像vector需要大量的操作，因为它的空间连续性是个假象。因此，deque的最大任务便是在这些分段的定量连续空间上，维护其整体连续的假象，并提供随机存取的接口。避开了“重新配置、复制、释放”的轮回，代价则是复杂的迭代器架构。 deque采用一块所谓的map作为主控，这里所谓的map是一小块连续空间，其中每个元素都是一个指针，指向另一段连续线性空间，称为缓冲区。缓冲区才是deque的储存空间主体。SGI STL允许我们指定缓冲区大小，默认值0表示将使用512bytes缓冲区。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yezhejack.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://yezhejack.github.io/tags/STL/"},{"name":"学习笔记","slug":"学习笔记","permalink":"http://yezhejack.github.io/tags/学习笔记/"}]},{"title":"python的web server","slug":"python的web server","date":"2016-04-13T11:21:58.000Z","updated":"2016-05-04T14:18:06.000Z","comments":true,"path":"2016/04/13/python的web server/","link":"","permalink":"http://yezhejack.github.io/2016/04/13/python的web server/","excerpt":"","keywords":null,"text":"shebang这个就是放在python代码的第一句。 1#!/usr/bin/env python 这个是为了让程序找到python的位置，如果这句话不起作用的话，可以直接使用完整的python路径。 CGI(Common Gateway Interface)服务器接收到动态请求的时候，请求CGI脚本，然后启动python程序，将URL请求转换为python的标准输入，然后从python程序的标准输出中获得返回内容。对于CGI来说，它是将python解释器嵌入到服务器本身中。 FastCGI &amp; SCGI这两种都是通过服务器本身和后台进程的交流来实现动态内容请求。SCGI可以理解为是一种simpler FastCGI。鉴于现在大多数的Web Server对其支持的缺乏，大家更倾向于使用FastCGI。 WSGIWSGI实际上是一个类似标准的东西，是对一种中间件的描述，当HTTP Server按照这个标准提供支持，应用本身也根据这个标准提供支持后，这两者就可以通过WSGI来进行沟通。需要强调的是这个是为python定制的标准。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"},{"name":"Web Server","slug":"Web-Server","permalink":"http://yezhejack.github.io/tags/Web-Server/"}]},{"title":"STL学习笔记-3－迭代器(iterators)概念与traits编程技法","slug":"STL学习笔记-3-1~3-3","date":"2016-04-13T07:04:55.000Z","updated":"2016-05-04T14:19:46.000Z","comments":true,"path":"2016/04/13/STL学习笔记-3-1~3-3/","link":"","permalink":"http://yezhejack.github.io/2016/04/13/STL学习笔记-3-1~3-3/","excerpt":"","keywords":null,"text":"auto_ptr1void remodel(string &amp; str) &#123; string * ps = new string(str); str = ps; return; &#125; 这段代码会造成内存泄漏，我们会想说在函数return之前记得delete ps即可避免内存泄漏。 123void remodel(string &amp; str) &#123; string * ps = new string(str); if (weird_thing()) throw exception(); str = *ps; delete ps; return; &#125; 但是这段代码在exception被抛出之后，delete这个句子不会被执行，也就造成了内存泄漏。 使用一个auto_ptr类型的话，在函数返回时，因为auto_ptr有自己的析构函数，所以会自己释放自己指向的内存空间。auto_ptr不能用于数组。 You should use an auto_ptr object only for memory allocated by new, not for memory allocated by new [] or by simply declaring a variable. 赋值操作在正常的指针操作中，指针指间的相互赋值实际上是让多个指针同时指向一个内存空间。但是这个应用到auto_ptr上时就会有问题了，但删除两个auto_ptr时会导致程序对同一个内存空间进行了多次的delete操作。 为了避免这一个问题，可以用下面几个策略来避免： 让赋值操作变成deep copy，这会让两个指针指向不同的内存空间，其中一个将作为另一个的拷贝。 构建ownership概念，也就是拥有者概念。一个对象只能有一个智能指针拥有，只有拥有这个对象的智能指针能析构这个对象。赋值的同时转换拥有权。 创建一个更加智能的指针，对指向特定对象的指针进行跟踪。这个叫做reference counting。 当一个指针放弃了自己的拥有权之后，它可能会转变为不可用的状态。 iterator 是一种smart pointerexplicit在类声明中使用这个可以避免隐形的转换。例如 123456789class Star&#123;...public: explicit Start(const char*);...&#125;; Star north;north=\"polaris\";//错误的使用方式north=Star(\"polaris\");//正确的使用方式 偏特化两个说法 提供一份template定义式，其本身仍然是templaized。 针对任何template参数更进一步的条件限制所设计出来的一个特化版本。 例如下面的代码接受任意类型 12template &lt;typename T&gt;class C&#123;...&#125; 而下面的代码只接受原生指针 12template &lt;typename T&gt;class C&lt;T&gt; &#123;...&#125; 下面是一段用于类型萃取的代码 1234template &lt;class I&gt;struct iterator_traits&#123; //traits意为特性 typedef typename I::value_type value_type&#125; 如果class I有自己的value_type的话 12345template&lt;class I&gt;typename iterator_traits&lt;I&gt;::valuetype //函数的返回类型func(I ite)&#123; return *ite;&#125; 但是这个萃取器对于原生指针，像int* I这样的类型并不起作用，因为它并不是由用户定义的，因此并没有在内部定义一个value_type。因此需要一个特化版本的iterator_traits。如下所示 1234template&lt;typename T&gt;struct iterator_traits&lt;T*&gt;&#123; typedef T value_type;&#125; 即使有这两个萃取器，对于像指向const int的指针类型的时候，我们只能获得一个无法更改的返回值。因此我们还需要另一个特化的萃取器。 1234template&lt;typename T&gt;struct iterator_traits&lt;const T*&gt;&#123; typedef T value_type;&#125; 最常用的迭代器(iterator)类型有物种: value type difference type pointer reference iterator catagoly 3.4.1 value type任何一个打算与STL配合的class都需要定义自己的value type内嵌型别。 3.4.2 difference typedifference type表示两个迭代器之间的距离。因此它可以用来表示一个容器的最大容量。如果需要提供一个计数功能count()的话，返回值就需要是difference type 12345678910template&lt;class I,class T&gt;typename iterator_traits&lt;I&gt;::difference_typecount(I first,I last,const T&amp; value)&#123; typename iterator_traist&lt;I&gt;::difference_type n=0; for (;first!=last;first++)&#123; if (*first==value) ++n; return n; &#125;&#125; 接着可以给出一个泛化版本的和两个特化版本的difference type的萃取器。 12345//泛化版本template &lt;class I&gt;struct iterator_traits&#123; typedef typename I::differene_type difference_type;&#125; 12345//为原生指针特化的版本template &lt;class T&gt;struct iterator_traits&lt;T*&gt;&#123; typedef ptrddif_t difference_type;&#125; 12345//为pointer to const偏特化的template &lt;class T&gt;struct iterator_traits&lt;const T*&gt;&#123; typedef ptrddif_t difference_type;&#125; 有了这三个萃取器，我们想要任何迭代器的difference type的时候我们只需要一下代码: 1typename iterator_traits&lt;class I&gt;::difference_type; reference type从迭代器所指之物的内容是否允许改变来看，可以将迭代器分为两种: 不允许改变所指对象之内容，称为constant iterators。例如const int* pic。 允许改变所指对象之内容，称为mutable iterators。例如int* pi。 当p是一个mutable iterators时，如果其value type是T，那么*p的型别不应是T，而应该是&amp;T。以此类推，如果p是一个constant iter，其value type是T，那么*p的型别应该是const T&amp;。这里所讨论的*p就是所谓的reference type。 pointer type12Item&amp; operator* () const&#123; return *ptr;&#125;Item* operator-&gt;() const &#123; return ptr;&#125; Item&amp;便是reference type，而Item*便是其pointer type。 直接献上完整的代码(Orz): 1234567891011121314151617181920212223242526template &lt;class Iterator&gt;struct iterator_traits &#123; typedef typename Iterator::iterator_category iterator_category; typedef typename Iterator::value_type value_type; typedef typename Iterator::difference_type difference_type; typedef typename Iterator::pointer pointer; typedef typename Iterator::reference reference;&#125;;template &lt;class T&gt;struct iterator_traits&lt;T*&gt; &#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;template &lt;class T&gt;struct iterator_traits&lt;const T*&gt; &#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef const T* pointer; typedef const T&amp; reference;&#125;; iterator_category根据移动特性与施行操作，迭代器被分为五类: input iterator:这种迭代器所指的对象，不允许外界改变。只读(read only)。 output iterator:write only。 forward iterator:允许“写入型”算法（例如replace()）在此迭代器所形成的区间上进行读写操作。 bidirectional iterator:可双向移动。某些算法需要逆向走访某个迭代器区间（例如逆向拷贝某范围内的元素），可以使用这种迭代器。 random access iterator:前四种迭代器都只供应一部分指针算数能力（前三种支持operator++，第四种再加上operator–），第五种则涵盖所有指针算数能力，包括p+n``p-n``p[n]``p1-p2``p1&lt;p2。 advance()这是许多算法内部常用的一个函数，该函数有两个参数p和n。表示函数将p累进n次。下面有三份定义，分别针对Input Iterator``Bidirectional Iterator``Random Access Iterator。而对ForwardIterator来说，它的版本与Input Iterator的版本一致。 123456template &lt;class InputIterator, class Distance&gt;void advance_II(InputIterator&amp; i,Distance n)&#123; //单向，逐一前进 while(n--) ++i;&#125; 123456789template &lt;class BidirectionalIterator, class Distance&gt;void advance_BI(BidirectionalIterator&amp; i,Distance n)&#123; //双向，逐一前进 if (n&gt;=0) while (n--) ++i; else while (n++) --i;&#125; 123456template &lt;class RandomAccessIterator, class Distance&gt;void advance_RAI(RandomAccessIterator&amp; i,Distance n)&#123; //双向，跳跃前进 i+=n;&#125; 但是这样的话我们还需要一个函数来判断迭代器的类型然后调用相应的函数。 定义五个classes 12345struct input_iterator_tag &#123;&#125;;struct output_iterator_tag &#123;&#125;;struct forward_iterator_tag : public input_iterator_tag &#123;&#125;;struct bidirectional_iterator_tag : public forward_iterator_tag &#123;&#125;;struct random_access_iterator_tag : public bidirectional_iterator_tag &#123;&#125;; 设计五个用于内部调用的函数，最后一个参数只是为了激活函数的重载。 1234template &lt;class InputIterator, class Distance&gt;inline void __advance(InputIterator&amp; i, Distance n, input_iterator_tag) &#123; while (n--) ++i;&#125; 12345678template &lt;class BidirectionalIterator, class Distance&gt;inline void __advance(BidirectionalIterator&amp; i, Distance n, bidirectional_iterator_tag) &#123; if (n &gt;= 0) while (n--) ++i; else while (n++) --i;&#125; 12345template &lt;class RandomAccessIterator, class Distance&gt;inline void __advance(RandomAccessIterator&amp; i, Distance n, random_access_iterator_tag) &#123; i += n;&#125; 这里使用的方法是添加一个单纯的调用函数advance()，这个函数只接受两个参数，当它将工作转向__advance()的时候，自行通过traits机制加上第三个参数，也就是前面定义的五个classes。 1234template &lt;class InputIterator, class Distance&gt;inline void advance(InputIterator&amp; i, Distance n) &#123; __advance(i, n, iterator_category(i));&#125; 然后再定义函数iterator_category()。 123456template &lt;class Iterator&gt;inline typename iterator_traits&lt;Iterator&gt;::iterator_categoryiterator_category(const Iterator&amp;) &#123; typedef typename iterator_traits&lt;Iterator&gt;::iterator_category category; return category();&#125; 可以注意到我们在列举__advance()函数的时候，少列举了两种，一种是OutputIterator，另一种是ForwardIterator。前者是因为可以同InputIterator共用，后者是因为可以消除单纯只做传递调用的函数，所以就没有对应的__advance()函数了。 __types_traits这个技巧类似于前面的iterator_traits，都是用于解析特征。这里需要解析看这个类型能否使用更快速的内存上的操作进行操作，避免使用高层次的函数。 使用场景：uninitialized_fill_n()12345template &lt;class ForwardIterator, class Size, class T&gt;inline ForwardIterator uninitialized_fill_n(ForwardIterator first, Size n, const T&amp; x) &#123; return __uninitialized_fill_n(first, n, x, value_type(first));&#125; 上面这个函数以x为蓝本，自迭代器first开始构造n个元素。为求取最大效率，首先以value_type()萃取出迭代器first的value type，再利用__type_traits判断该型别是否为POD型别： 1234567template &lt;class ForwardIterator, class Size, class T, class T1&gt;inline ForwardIterator __uninitialized_fill_n(ForwardIterator first, Size n, const T&amp; x, T1*) &#123; typedef typename __type_traits&lt;T1&gt;::is_POD_type is_POD; return __uninitialized_fill_n_aux(first, n, x, is_POD()); &#125; 接着调用了上面这个函数，其中is_POD()是一个struct，然后调__uninitialized_fill_n_aux函数，其中编译器会根据is_POD()来重载函数，分配到是POD和不是POD对应的函数中。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yezhejack.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://yezhejack.github.io/tags/STL/"},{"name":"学习笔记","slug":"学习笔记","permalink":"http://yezhejack.github.io/tags/学习笔记/"}]},{"title":"STL学习笔记-2.3内存基本处理工具","slug":"STL学习笔记-2-3内存基本处理工具","date":"2016-04-12T08:15:20.000Z","updated":"2016-05-04T14:19:33.000Z","comments":true,"path":"2016/04/12/STL学习笔记-2-3内存基本处理工具/","link":"","permalink":"http://yezhejack.github.io/2016/04/12/STL学习笔记-2-3内存基本处理工具/","excerpt":"","keywords":null,"text":"2.3 内存基本处理工具这里面主要包括了三个函数 uninitialized_copy() uninitialized_fill() uninitialized_fill_n() 对应着高层次的函数 copy() fill() fill_n() 这些都是STL算法。 uninitialized_copy()讲某一区间的内容复制到另一个区间： 配置内存区块，足以包含范围内的所有元素 使用该函数，在该内存区块上构造元素 C++标准中要求这个函数具有“commit or rollback”的语义，其实也就是让这个操作原子话，当某个copy constructor失败时回滚所有已发生的操作。 接受三个参数: 迭代器first指向输入端的起始位置 迭代器last指向输入端的结束位置（前闭后开区间）。 迭代器result指向输出端（欲初始化空间）的起始处。 uninitialized_fill()对于范围内的所有区块，都构造一个给定的内存内容。同样要求有原子性。 uninitialized_fill_n()类似前者，从first位置开始，构造n个第三参数的复制品。同样也在标准中要求原子性 本函数接受三个参数: 迭代器first指向欲初始化空间的起始处。 n表示欲初始化空间的大小 x表示初值 12345template &lt;class ForwardIterator, class Size, class T&gt;inline ForwardIterator uninitialized_fill_n(ForwardIterator first, Size n, const T&amp; x) &#123; return __uninitialized_fill_n(first, n, x, value_type(first));&#125; 这段代码先取出迭代器first的value type，然后判断该类别是否为POD类别。POD也就是Plain Old Data也就是标量型或传统的C struct类别。POD类别拥有trivial ctor／dtor／copy／assignment函数，因此对POD类别采用最有效率的初值填写手法，而对非POD类别采用最保险安全的做法。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yezhejack.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://yezhejack.github.io/tags/STL/"},{"name":"学习笔记","slug":"学习笔记","permalink":"http://yezhejack.github.io/tags/学习笔记/"}]},{"title":"STL学习笔记-1.1~2.2","slug":"STL学习笔记-1.1~2.2","date":"2016-04-09T14:20:32.000Z","updated":"2016-05-04T14:19:05.000Z","comments":true,"path":"2016/04/09/STL学习笔记-1.1~2.2/","link":"","permalink":"http://yezhejack.github.io/2016/04/09/STL学习笔记-1.1~2.2/","excerpt":"","keywords":null,"text":"笔记p45出现了::operator new和::operator delete，这个地方比较难理解。首先，先把new和delete当作一个操作符，因此要重载它的时候需要加个operator。 1::operator new 这个语句的意思是在全局命名空间下的new操作符。 重要概念模版特化函数模版特化比如设置了一个带有模版的函数，但是我想对其中的某种类型参数的函数进行单独定义。如果不含有这个机制的话，编译器会将其匹配到原始的模版函数中。例如 12345template &lt;class T&gt;T max(T a,T b)&#123; return a&lt;b ? b:a;&#125; 如果我想使用这个模版函数来处理字符串 123char* p1=\"hello\";char* p2=\"world\";char* p3=max(p1,p2); 这时候会单纯地比较p1和p2两个指针数值本身的大小，而非对应的字符串。所以我们需要特化。 12345template&lt;&gt;char* max(char* a,char* b)&#123; returan (strcmp(a,b)&lt;0)?b:a;&#125; 这样才能让程序正确地被编译出来。 类模版特化1234template &lt;class T&gt;class stack &#123;&#125;;template &lt; &gt;class stack&lt;bool&gt; &#123; //…// &#125;; 偏特化偏特化的意思就是对某些参数给定类型的时候给出特化方案。 类模版特化 1234template &lt;class T, class Allocator&gt;class vector &#123; // … // &#125;;template &lt;class Allocator&gt;class vector&lt;bool, Allocator&gt; &#123; //…//&#125;; 函数模版特化 严格的来说，函数模板并不支持偏特化，但由于可以对函数进行重载，所以可以达到类似于类模板偏特化的效果。 1template &lt;class T&gt; void f(T); (a) 根据重载规则，对（a）进行重载 1template &lt; class T&gt; void f(T*); (b) 如果将（a）称为基模板，那么（b）称为对基模板（a）的重载，而非对（a）的偏特化。C++的标准委员会仍在对下一个版本中是否允许函数模板的偏特化进行讨论。 memorystd::allocator这个文件是旧式做法的配置器。不建议使用它，所有的SGI STL头文件都没有包含它。 SGI的std::allocator只是对::operator new和::operator delete做了一层薄薄的包装。 stl_alloc.h 负责内存空间的配置与释放 包含了一二级的配置器，彼此合作。 设计哲学 向system heap要求空间 考虑多线程（multi-threads)状态。 考虑内存不足时的应变措施。 考虑过多的“小型区块”可能造成的内存碎片（fragment）问题。 当需要的区块大于128 Bytes的时候，会使用一级配置器来分配内存，如果是小于的话，则利用二级配置器，从free list中获取。 SGI STL缺省使用的空间配置器并不是标准的allocator，而是alloc。它在所有的需要空间配置器的类中使用的都是alloc。 例如 12template &lt;class T,class Alloc=alloc&gt;class vector &#123;...&#125;; 一级配置器:__malloc_alloc_template 二级配置器:__default_alloc_template 无论是一级还是二级配置器，SGI都为其包装了一层薄薄的借口，使之能够符合STL的标准: 12345678910111213template&lt;class T, class Alloc&gt;class simple_alloc &#123;public: static T *allocate(size_t n) &#123; return 0 == n? 0 : (T*) Alloc::allocate(n * sizeof (T)); &#125; static T *allocate(void) &#123; return (T*) Alloc::allocate(sizeof (T)); &#125; static void deallocate(T *p, size_t n) &#123; if (0 != n) Alloc::deallocate(p, n * sizeof (T)); &#125; static void deallocate(T *p) &#123; Alloc::deallocate(p, sizeof (T)); &#125;&#125;; free list这个结构存储这个多个区块，同时拥有一个节点的数据结构 1234union obj &#123; union obj * free_list_link; char client_data[1]; /* The client sees this. */ &#125;; 这个结构的就只包含一个指针，在64位系统中，这个指针的大小位8个字节。因此在free list中，如果想要存储小于8个字节的区块时是会失败的。每个区块实际上都存着一个obj结构。这里的设计的妙处在于，我们通常都会用一个节点结构，这个节点结构后面再挂着实际区块。例如 1234struct obj&#123; struct obj* next_obj; char* addr;&#125;; chunk_alloc()这样我们就需要16个字节来表示一个区块，而且这16个字节还不是区块本身的字节。因此孰优孰劣，一目了然。 stl_construct.h负责对象内容的构造与析构 其中的__type_traits&lt;&gt; 将在3.7节中有详细介绍。","raw":null,"content":null,"categories":[{"name":"Learning","slug":"Learning","permalink":"http://yezhejack.github.io/categories/Learning/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://yezhejack.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://yezhejack.github.io/tags/STL/"}]},{"title":"安装libsvm和gnuplot","slug":"安装libsvm和gnuplot","date":"2016-03-28T09:07:22.000Z","updated":"2016-05-04T14:10:32.000Z","comments":true,"path":"2016/03/28/安装libsvm和gnuplot/","link":"","permalink":"http://yezhejack.github.io/2016/03/28/安装libsvm和gnuplot/","excerpt":"","keywords":null,"text":"安装libsvm安装 直接下载源码，然后进入目录make 安装gnuplot安装 下载源码 1234cd 目录./configuremakesudo make install 可能遇到的问题 我是在使用libsvm的easy.py来测试的时候遇到无法检测出gnuplot存在，查其原因，可能是因为在/usr/bin目录下没有看到gnuplot，而是在/usr/local/bin中有。因此需要找到方法让别的程序能找到安装的gnuplot。 解决方案：将/usr/local/bin/gnuplot拷贝到/usr/bin下。或者，将easy.py中的关于gnuplot的路径改为/usr/local/bin。","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"libsvm","slug":"libsvm","permalink":"http://yezhejack.github.io/tags/libsvm/"},{"name":"gnuplot","slug":"gnuplot","permalink":"http://yezhejack.github.io/tags/gnuplot/"}]},{"title":"nginx","slug":"nginx","date":"2015-12-21T16:26:18.000Z","updated":"2016-07-21T08:39:03.000Z","comments":true,"path":"2015/12/22/nginx/","link":"","permalink":"http://yezhejack.github.io/2015/12/22/nginx/","excerpt":"","keywords":null,"text":"123456789101112131415161718+ using PCRE library: /mnt/application/pcre-8.32 + OpenSSL library is not used + using builtin md5 code + sha1 library is not found + using zlib library: /mnt/application/zlib-1.2.8 nginx path prefix: \"/usr/local/nginx\" nginx binary file: \"/usr/local/nginx/sbin/nginx\" nginx configuration prefix: \"/usr/local/nginx/conf\" nginx configuration file: \"/usr/local/nginx/conf/nginx.conf\" nginx pid file: \"/usr/local/nginx/logs/nginx.pid\" nginx error log file: \"/usr/local/nginx/logs/error.log\" nginx http access log file: \"/usr/local/nginx/logs/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" 从源码安装nginx拷贝nginx 到sbin分析access.log 访问量access.log是记录了所有的nginx的访问链接，并且纪录了这些访问的结果。可以使用python中的正则表达式来对其进行解析。这里需要python的re模块 123456789101112131415161718import reip = r\"?P&lt;ip&gt;[\\d.]*\"date = r\"?P&lt;date&gt;\\d+\"month = r\"?P&lt;month&gt;\\w+\"year = r\"?P&lt;year&gt;\\d+\"log_time = r\"?P&lt;time&gt;\\S+\"method = r\"?P&lt;method&gt;\\S+\"request = r\"?P&lt;request&gt;\\S+\"status = r\"?P&lt;status&gt;\\d+\"bodyBytesSent = r\"?P&lt;bodyBytesSent&gt;\\d+\"refer = r\"\"\"?P&lt;refer&gt; [^\\\"]* \"\"\"userAgent=r\"\"\"?P&lt;userAgent&gt; .* \"\"\"p = re.compile(r\"(%s)\\ -\\ -\\ \\[(%s)/(%s)/(%s)\\:(%s)\\ [\\S]+\\]\\ \\\"(%s)?[\\s]?(%s)?.*?\\\"\\ (%s)\\ (%s)\\ \\\"(%s)\\\"\\ \\\"(%s).*?\\\"\" %( ip, date, month, year, log_time, method, request, status, bodyBytesSent, refer, userAgent ), re.VERBOSE)m = re.findall(p, line) 分割access.log安装方法1以ubuntu 14.04为例，其中的codename是trusty因此需要把下面的代码追加到12 deb http://nginx.org/packages/ubuntu/ trusty nginxdeb-src http://nginx.org/packages/ubuntu/ trusty nginx12然后运行 sudo apt-get updatesudo apt-get install nginx123456这个安装方式有问题的### 安装方法2 ####### 安装pcre #### cd /usr/local/srcsudo wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.37.tar.gzsudo tar -zxvf pcre-8.37.tar.gzcd pcre-8.34sudo ./configuresudo makesudo make install12#### 安装zlib #### cd /usr/local/srcsudo wget http://zlib.net/zlib-1.2.8.tar.gzsudo tar -zxvf zlib-1.2.8.tar.gzcd zlib-1.2.8/sudo ./configuresudo makesudo make install12#### 安装ssl #### cd /usr/local/srcsudo wget https://www.openssl.org/source/openssl-1.0.1t.tar.gzsudo tar -zxvf openssl-1.0.1t.tar.gz12#### 安装 nginx #### cd /usr/local/srcwget http://nginx.org/download/nginx-1.8.1.tar.gztar -zxvf nginx-1.8.1.tar.gzcd nginx-1.8.1.tar.gzsudo ./configure –sbin-path=/usr/local/nginx/nginx –conf-path=/usr/local/nginx/nginx.conf –pid-path=/usr/local/nginx/nginx.pid –with-http_ssl_module –with-pcre=/usr/local/src/pcre-8.37 –with-zlib=/usr/local/src/zlib-1.2.8 –with-openssl=/usr/local/src/openssl-1.0.1tsudo makesudo make install```","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Server","slug":"Server","permalink":"http://yezhejack.github.io/tags/Server/"},{"name":"Nginx","slug":"Nginx","permalink":"http://yezhejack.github.io/tags/Nginx/"}]},{"title":"linux常见操作","slug":"linux常见操作","date":"2015-12-20T08:23:15.000Z","updated":"2016-08-21T04:32:10.000Z","comments":true,"path":"2015/12/20/linux常见操作/","link":"","permalink":"http://yezhejack.github.io/2015/12/20/linux常见操作/","excerpt":"","keywords":null,"text":"用户管理增加一个用户1useradd -g &lt;初始组名称&gt; -G &lt;附属组名称&gt; -m -d /home/&lt;username&gt; -s /bin/bash &lt;username&gt; 12useradd -g benben -G sudo -m -d /home/zhangsan -s /bin/bash zhangsanpasswd zhangsan 上面新建了一个用户，属于笨笨组的，同时也属于sudo组，拥有sudo权限，是个拥有很高权限的管理员，仅次于root。同时他的目录定义在了/home/zhangsan，同时将shell指定为/bin/bash，第二句话会设置一个密码。 如果只是一个普通的用户，不希望让他拥有sudo权限的话，将-G参数去掉，只让他属于benben组即可。这样这个帐户就无法安装东西，必须联系管理员才能进行安装。 公共工作空间为了让大家共同合作，可以利用管理员账户建立一个目录，这个目录的组别属于benben，也就是需要合作的人的共同组别。然后将这个目录的属于组修改为benben。 1chgrp -R benben /mnt/benben 然后再修改这个目录的权限为775，也就是rwx rwx r_x，拥有者和组成员拥有读、写、执行权限，而其他人只拥有读、执行权限。 1chmod 775 /mnt/benben 为用户增加sudo权限登陆到root账号，然后输入下面的命令，以zhangsan这个用户为例 1usermod -G sudo zhangsan 也可以在/etc/group中在sudo后面加上zhangsan 增加用户到另一个用户组中我新建了一个用户yezhe，然后想要把它增加到用户组sudo中，以便于使用sudo命令，这里需要使用root用户 1usermod -G sudo yezhe 更改用户的工作目录需要用root权限 1usermod -d /home/yezhe yezhe 如果出现一个用户在命令行无法显示名字和路径这个情况下我在更改了/etc/passwd之后就可以了，也就是给它添加一个shell，一般默认是和root一样用同一个shell:/bin/bash screen设置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# Set default encoding using utf8defutf8 on## 解决中文乱码,这个要按需配置defencoding utf8encoding utf8 utf8 #兼容shell 使得.bashrc .profile /etc/profile等里面的别名等设置生效shell -$SHELL#set the startup messagestartup_message offterm linux## 解决无法滚动termcapinfo xterm|xterms|xs ti@:te=\\E[2J # 屏幕缓冲区行数defscrollback 10000 # 下标签设置hardstatus oncaption always \"%&#123;= kw&#125;%-w%&#123;= kG&#125;%&#123;+b&#125;[%n %t]%&#123;-b&#125;%&#123;= kw&#125;%+w %=%d %M %0c %&#123;g&#125;%H%&#123;-&#125;\" #关闭闪屏vbell off #Keboard binding# bind Alt+z to move to previous windowbindkey ^[z prev# bind Alt+x to move to next windowbindkey ^[x next# bind Alt`~= to screen0~12bindkey \"^[`\" select 0bindkey \"^[1\" select 1bindkey \"^[2\" select 2bindkey \"^[3\" select 3bindkey \"^[4\" select 4bindkey \"^[5\" select 5bindkey \"^[6\" select 6bindkey \"^[7\" select 7bindkey \"^[8\" select 8bindkey \"^[9\" select 9bindkey \"^[0\" select 10bindkey \"^[-\" select 11bindkey \"^[=\" select 12# bind F5 to create a new screenbindkey -k k5 screen# bind F6 to detach screen session (to background)bindkey -k k6 detach# bind F7 to kill current screen windowbindkey -k k7 kill``# bind F8 to rename current screen windowbindkey -k k8 title 在screen中，一个session中可以包含多个windows C-a A 用于修改当前标签的名字 C-a k 关闭当前windows 运维方案 这个方案以ubuntu 14.04 为例，并且是使用vultr的服务器。 修改root账号的密码 登录root账号 使用 passwd root命令，即可根据提示修改密码 增加个人用户，并使其拥有sudo权限123useradd -d /home/zhangsan -m zhangsanpasswd zhangsanusermod -G sudo zhangsan 第一行的命令同时为zhangsan这个账户增加了一个工作目录，第二行为修改密码，第三行为修改这个账户的权限，将其加入到sudo的组中，到此为止一个简单的linxu远程服务器的用户部分就已经配置好了。 查看进程1ps aux|grep &lt;name&gt; 查看主机最近一次的启动时间1who -b 在高性能服务器上跑训练标准输出重定向1command &gt; out.put 2&gt;&amp;1 command就是我们要跑的程序。out.put就是我们希望把屏幕上输出的内容存入的文件，比如我希望明天一早起来看到一个程序的结尾，但是我又不想改这个程序让其把最后的算法结果存入某个程序（其实就是懒）。2表示标准输出，而1表示标准错误输出。另外提一句0就是表示标准输入，这些都是一个进程的默认的文件描述符，unix中一切皆文件。 如果中间的符号改为&gt;&gt;的话，是以追加的方式写文件。 查看cpu信息1cat /proc/cpuinfo 使用nologin运行程序1sudo -u nologin &lt;cmd&gt; top命令改变RES（实际占用的物理内存大小）12e 是切换任务区域的E 切换总结区域的 查看文件夹大小1du -h --max_depth=1 公钥登录生成本地的公钥1ssh-keygen 然后将其复制到远程主机上1ssh-copy-id -p port username@remotehost 如果有问题的话，可能是.ssh和authorized_keys这两个东西的权限的有问题，正常情况下分别是700和600的权限。 可以在linux远程主机上的~/.profile里加上一句话screen -r &lt;name&gt;这样子可以一登录就重启之前启动好的screen。千万不能变成screen -R &lt;name&gt;。否则会陷入死循环。 alias 命令别名在实际使用中，需要登录的机器的名字太长了，所以可以设置一些别名，用这些别名来代替真正的命令行。 1vim ~/.bash_profile 然后输入 1alias to_host=\"ssh yezhe@remotehost\" 保存退出后让其生效 1source ~/.bash_profile 这时候使用1to_host 就可以直接登录了，而且还支持补全代码，也就是tab。 locale 设置生成空白文件1dd if=/dev/zero of=hello.txt bs=100M count=1 supervisorsupervisor是一个进程管理，在我们远程登录server的时候会启动一个bash，但是这个bash我们退出ssh之后就消失了，里面的进程也就消失了。于是我们需要一个进程管理，我们将想要启动的进程扔给它，由它来管理即可。screen可以是一个不错的进程管理，可以用来debug，因为它可以前端显示，但是本质也还是后台启动。 但是最近在使用一个开源工具，这个工具的crash的频率比较高，因此需要一个能够自动重启carsh进程的进程管理，那就是supervisor 安装1easy_install supervisor 这个命令可以在屏幕上打印出配置信息 1echo_supervisord_conf 然后将配置输入到/etc路径中，这个需要root权限1echo_supservisord_conf &gt; /etc/supervisord.conf 启动如果supdervirod的二进制文件是安装在系统的PATH下的话，是可以直接启动的 新建一个文件夹/etc/supervisor/然后在/etc/supervisord.conf中的include项中加入 12[include]files = /etc/supervisor/*.conf 然后填写一个需要启动的程序的配置文件12345678910111213141516[program:phantomjs]directory = /data/pyspider ; 程序的启动目录command = pyspider -c ./config/pyspider.json phantomjs ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = yezhe ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/pyspider/log/phantomjs.log; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 输出日期12echo `date`echo `date +%Y-%m-%d-%H-%M-%S` cron command not found这个问题的原因在于cron在运行时的环境变量不一样，其中的$PATH会被 查看当前文件夹下的文件个数和文件夹个数1ls -l |grep \"^-\"|wc -l 转载自http://blog.sina.com.cn/s/blog_464f6dba01012vwv.html统计某文件夹下文件的个数 1ls -l |grep \"^-\"|wc -l 统计某文件夹下目录的个数 1ls -l |grep \"^ｄ\"|wc -l 统计文件夹下文件的个数，包括子文件夹里的 1ls -lR|grep \"^-\"|wc -l 如统计/home/han目录(包含子目录)下的所有js文件则： 1ls -lR /home/han|grep js|wc -l 或 ls -l \"/home/han\"|grep \"js\"|wc -l 统计文件夹下目录的个数，包括子文件夹里的 1ls -lR|grep \"^d\"|wc -l 说明： 1ls -lR 长列表输出该目录下文件信息(R代表子目录注意这里的文件，不同于一般的文件，可能是目录、链接、设备文件等) 1grep \"^-\" 这里将长列表输出信息过滤一部分，只保留一般文件，如果只保留目录就是 ^d 1wc -l 统计输出信息的行数，因为已经过滤得只剩一般文件了，所以统计结果就是一般文件信息的行数，又由于一行信息对应一个文件，所以也就是文件的个数。 ＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝如果只查看文件夹ls -d 只能显示一个.find -type d 可以看到子文件夹ls -lF |grep / 或 ls -l |grep &#39;^d&#39; 只看当前目录下的文件夹，不包括往下的文件夹","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yezhejack.github.io/tags/服务器/"}]},{"title":"redis","slug":"redis","date":"2015-12-20T08:23:15.000Z","updated":"2016-05-27T06:01:13.000Z","comments":true,"path":"2015/12/20/redis/","link":"","permalink":"http://yezhejack.github.io/2015/12/20/redis/","excerpt":"","keywords":null,"text":"安装1234wget http://download.redis.io/releases/redis-3.0.6.tar.gztar xzf redis-3.0.6.tar.gzcd redis-3.0.6make 启动redis1src/redis-server 会在前台启动，然后再启动客户端来进行测试1src/redis-cli 可以在测试端里写1set foo bar 然后再写1get foo bar 分别对应着存取操作 安装redis-py1sudo easy_install redis 安装hiredis1pip install hiredis 这个parser的效率比较高 后台启动redis修改redis目录下的redis.conf文件，将其中的1daemonize no 修改为1daemonize yes 然后关闭刚才在前台启动的redis-server，进入到redis的目录1src/redis-server ./redis.conf 即可启动redis 关闭后台redis打开redis-cli，输入1shutdown save 即可安全退出redis，后面的save表示会保存之后再退出，如果是nosace则是马上退出，有可能会存在数据丢失 配置redis安全选项12rename-command FLUSHALL BENBENREDISFLUSHALLrename-command FLUSHDB BENBENREDISFLUSHDB 将FLUSHALL操作变为BENBENREDISFLUSHALL,将FLUSHDB变为BENBENREDISFLUSHDB,以降低开发过程中不小心将数据全部清空的概率 python 操作初始化123import redisr=redis.StrictRedis(host='localhost',port=6379,db=0) listlpush &amp;&amp; rpushlpush对应在list头加入元素，rpush对应在list尾加入元素lrange可以取出对应范围的元素比如要往一个叫做alist的list里append一个数据，可以直接用1r.rpush('alist',value1,value2...) 后面跟至少一个参数运行1r.lrange('alist',0,-1) 取出alist中的所有数据，返回类型是一个string类型的list1r.lindex('alist',pos) 等价于alist[pos] dicthashpython中的dict类型对应在redis中的类型是hash hmset这是可以直接把python中的dict一次性存入redis的命令12dict_a=&#123;'a':1,'b':2&#125;r.hmset('dict_a',dict_a) 这就直接把一个叫做dict_a的dict存入了redis中，并且这个名字保持一致 hgetall想要一次性把dict_a全部取出来1dict_a=r.hgetall('dict_a') hget读取key对应的value1value=r.hget('dict_a','a') hdel用来删除dict中对应的键值1r.hdel('dict_a','key') mset mget```r.mset({‘name1’:value1,’name2’:value2})r.mget(‘name1’,’name2’)","raw":null,"content":null,"categories":[{"name":"Programmer","slug":"Programmer","permalink":"http://yezhejack.github.io/categories/Programmer/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"},{"name":"redis","slug":"redis","permalink":"http://yezhejack.github.io/tags/redis/"},{"name":"内存","slug":"内存","permalink":"http://yezhejack.github.io/tags/内存/"},{"name":"内存型数据库","slug":"内存型数据库","permalink":"http://yezhejack.github.io/tags/内存型数据库/"}]},{"title":"mpv播放器使用指南","slug":"mpv播放器使用指南","date":"2015-12-20T08:23:15.000Z","updated":"2016-08-28T13:46:54.000Z","comments":true,"path":"2015/12/20/mpv播放器使用指南/","link":"","permalink":"http://yezhejack.github.io/2015/12/20/mpv播放器使用指南/","excerpt":"","keywords":null,"text":"mpv播放器这是我觉得在mac os x平台上最好用的播放器了，耗电量正常情况下都很好。 homebrew安装解决字幕乱码在~/.config/mpv.conf中增加1subcp=enca:zh:cp936","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"mpv","slug":"mpv","permalink":"http://yezhejack.github.io/tags/mpv/"},{"name":"视频播放器","slug":"视频播放器","permalink":"http://yezhejack.github.io/tags/视频播放器/"}]},{"title":"Git以及GitHub的用法","slug":"git以及github的用法","date":"2015-12-10T09:48:00.000Z","updated":"2016-05-04T15:54:35.000Z","comments":true,"path":"2015/12/10/git以及github的用法/","link":"","permalink":"http://yezhejack.github.io/2015/12/10/git以及github的用法/","excerpt":"","keywords":null,"text":"删除远程分支当你刚刚在本地删除了一个分支，你想要让这个变化反应在远程的repo中的话1git push origin :&lt;branch name&gt; 假设你的branch的名字是simple那么需要的命令就是1git push origin :simple 推送新建分支到远程仓库在本地新建了一个分支，然后觉得这个分支写得好于是就可以推送到远程的仓库中。1git push origin &lt;branch name&gt; 从git中删除文件，但是保存在硬盘上1git rm --cached &lt;filename&gt; 重命名一个分支并且让这个作用到远程分支上123git branch -m simple devgit push origingit push origin :simple","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"版本管理","slug":"版本管理","permalink":"http://yezhejack.github.io/tags/版本管理/"},{"name":"Git","slug":"Git","permalink":"http://yezhejack.github.io/tags/Git/"},{"name":"GitHub","slug":"GitHub","permalink":"http://yezhejack.github.io/tags/GitHub/"}]},{"title":"python学习","slug":"python学习","date":"2015-12-10T09:22:36.000Z","updated":"2016-10-13T08:40:07.000Z","comments":true,"path":"2015/12/10/python学习/","link":"","permalink":"http://yezhejack.github.io/2015/12/10/python学习/","excerpt":"","keywords":null,"text":"xrangexrange和range函数的区别只在于节省空间，而且xrange是一个不透明的序列结构，range在使用的时候就已经创建了所有的序列，而xrange在使用到的时候才会有真正的值，常用于loop结构。它实际上只支持了索引，迭代和长度函数。 stripstring类型对应的函数，用于去除一些特殊符号，例如 \\n \\t 等，没有参数的话会去除多个，如果有参数的话则会根据参数去除。但是按照2.7版本的官方文档来说只是去除了空格，但是实际上还去除了换行符等，不知道是不是版本的问题。 argument parse getopt(C stytle) argparse 初始化 1234567import argparse#新建一个解析器（应该是这么翻译的）parser=argparse.ArgumentParser()#增加一个开关变量parser.add_argument(\"-v\",\"--verbose\",help=\"increate output verbosity\",action=\"store_true\")#获得变量args=parser.parse_args() 这个变量有一个缩写的名字-v，完整的名字是–verbose,并且是个开关变量，即标志，这里因为’action=”store_true”‘，因此有这个参数出现的时候，就代表了args.vebosity=True,当’action=count’时，会是一个计数器 使用args是一个带有所有参数变量的结构体（类） 限定输入参数的类型 1parser.add_argument(\"-v\",\"--verbosity\",type=int,help=\"balabalabala\") 位置参数和可选参数暂时还没搞懂这个区别，甚至是翻译是否正确也不知道(positional argument and optional argument) 默认参数可以用一个默认的和args相同尺寸的结构体来代替 12345parser=argparse.ArgumentParser(argument_default=argparse.SUPPRESS)parser.add_argument('--foo')parser.add_argument('bar',nargs='?')parser.parse_args(['--fool','1','BAR'])parser.parse_args([]) 还没实验，有问题还有另外一个方法，就是在parser.add_argument的最后加一个dafault=默认值 获得路径 获得当前工作路径12import osos.getcwd() 编码错误如果碰到这个问题1'ascii' codec can't encode characters in position 0-15: ordinal not in range(128) 可以用下面的代码来解决123import sysreload(sys)sys.setdefaultencoding('utf8') 修改开源组件因为项目需要加打log，所以需要修改开源组件webpy来进行纪录log。默认情况下webpy会被安装在’/usr/local/lib/python2.7/dist-packages’这个目录下，你需要删除webpy相关的几个东西，看名字就可以知道了，如果只是重新编译并安装的话是没有用的，有些地方无法覆盖 内存分析工具meliae安装123sudo apt-get install python-pipsudo apt-get install Cythonsudo pip install meliae dump内存12from meliae import scannerscanner.dump_all_objects('/opt/log/dump.txt') 分析内存12345from meliae import loaderom = loader.load('/opt/log/dump.txt')om.compute_parents()om.collapse_instance_dicts()om.summarize() 排序算法文件锁最近遇到一个问题，我需要跑N个进程的训练程序，然后我想有序地输出结果到文件中，并且是以追加的形式，因此我要在打开文件之前就 非root安装third party modules1pip install --user &lt;包名&gt;","raw":null,"content":null,"categories":[{"name":"Programmer","slug":"Programmer","permalink":"http://yezhejack.github.io/categories/Programmer/"}],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"http://yezhejack.github.io/tags/编程语言/"},{"name":"python","slug":"python","permalink":"http://yezhejack.github.io/tags/python/"}]},{"title":"OS_X中安装虚拟linux服务器","slug":"OS-X中安装虚拟linux服务器","date":"2015-11-28T10:35:19.000Z","updated":"2016-05-05T00:43:26.000Z","comments":true,"path":"2015/11/28/OS-X中安装虚拟linux服务器/","link":"","permalink":"http://yezhejack.github.io/2015/11/28/OS-X中安装虚拟linux服务器/","excerpt":"","keywords":null,"text":"安装virtualbox安装Ubuntu这里使用14.04 LTS版本，因为主要是为乐运行一些程序，所以用的比较稳定的版本。设置VirtualBox的网络设置为桥接（bridge）模式，这样就能用宿主机的所在网段地址去用ssh访问，因为我希望这个server能够是透明的，这样我就可以肆无忌惮地用OS X的终端来直接使用。 设置SSH使用以下的命令12sudo apt-get updatesudo apt-get install openssh-server 输入1sudo ps -e|grep ssh 即可查看ssh服务是否启动了，如果有sshd，则说明服务已经启动了如果没有启动的话，输入1sudo service ssh start 查看ip地址1ifconfig 想要编译源代码通常想要编译源代码的话，需要安装一个build-essential的编译包，看名字就知道是用于编译的1sudo apt-get install build-essential 这个操作之后应该是能够帮你把常见的相关包安装上","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"OS X","slug":"OS-X","permalink":"http://yezhejack.github.io/tags/OS-X/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://yezhejack.github.io/tags/虚拟机/"},{"name":"MAC","slug":"MAC","permalink":"http://yezhejack.github.io/tags/MAC/"},{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yezhejack.github.io/tags/Ubuntu/"}]},{"title":"vimrc设置方法","slug":"vimrc设置方法","date":"2015-11-24T08:26:22.000Z","updated":"2016-05-05T00:43:35.000Z","comments":true,"path":"2015/11/24/vimrc设置方法/","link":"","permalink":"http://yezhejack.github.io/2015/11/24/vimrc设置方法/","excerpt":"","keywords":null,"text":".vimrc的位置OS X和Linux的系统中，全局的vimrc的位置是/usr/share/vim/.vimrc，这个是不用更改的，可能也不能更改，但是我们可以将其复制到~/目录下，也就是//目录下，然后再进行更改。因为这个目录下的.vimrc的优先级比前者高，所以会优先使用这个。 .vimrc的配置从网络上搜刮来的现成配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; General\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Sets how many lines of history VIM has to rememberset history=700\" Enable filetype pluginsfiletype plugin onfiletype indent on\" Set to auto read when a file is changed from the outsideset autoread\" With a map leader it's possible to do extra key combinations\" like &lt;leader&gt;w saves the current filelet mapleader = \",\"let g:mapleader = \",\"\" Fast savingnmap &lt;leader&gt;w :w!&lt;cr&gt;\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; VIM user interface\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Set 7 lines to the cursor - when moving vertically using j/kset so=7\" Turn on the WiLd menuset wildmenu\" Ignore compiled filesset wildignore=*.o,*~,*.pyc\"Always show current positionset ruler\" Height of the command barset cmdheight=2\" A buffer becomes hidden when it is abandonedset hid\" Configure backspace so it acts as it should actset backspace=eol,start,indentset whichwrap+=&lt;,&gt;,h,l\" Ignore case when searchingset ignorecase\" When searching try to be smart about cases set smartcase\" Highlight search resultsset hlsearch\" Makes search act like search in modern browsersset incsearch\" Don't redraw while executing macros (good performance config)set lazyredraw\" For regular expressions turn magic onset magic\" Show matching brackets when text indicator is over themset showmatch\" How many tenths of a second to blink when matching bracketsset mat=2\" No annoying sound on errorsset noerrorbellsset novisualbellset t_vb=set tm=500set number\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Colors and Fonts\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Enable syntax highlightingsyntax enablecolorscheme desertset background=dark\" Set extra options when running in GUI modeif has(\"gui_running\") set guioptions-=T set guioptions+=e set t_Co=256 set guitablabel=%M\\ %tendif\" Set utf8 as standard encoding and en_US as the standard languageset encoding=utf8\" Use Unix as the standard file typeset ffs=unix,dos,mac\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Files, backups and undo\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Turn backup off, since most stuff is in SVN, git et.c anyway...set nobackupset nowbset noswapfile\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Text, tab and indent related\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Use spaces instead of tabsset expandtab\" Be smart when using tabs ;)set smarttab\" 1 tab == 4 spacesset shiftwidth=4set tabstop=4\" Linebreak on 500 charactersset lbrset tw=500set ai \"Auto indentset si \"Smart indentset wrap \"Wrap lines\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Visual mode related\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Visual mode pressing * or # searches for the current selection\" Super useful! From an idea by Michael Naumannvnoremap &lt;silent&gt; * :call VisualSelection('f')&lt;CR&gt;vnoremap &lt;silent&gt; # :call VisualSelection('b')&lt;CR&gt;\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Moving around, tabs, windows and buffers\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Treat long lines as break lines (useful when moving around in them)map j gjmap k gk\" Map &lt;Space&gt; to / (search) and Ctrl-&lt;Space&gt; to ? (backwards search)map &lt;space&gt; /map &lt;c-space&gt; ?\" Disable highlight when &lt;leader&gt;&lt;cr&gt; is pressedmap &lt;silent&gt; &lt;leader&gt;&lt;cr&gt; :noh&lt;cr&gt;\" Smart way to move between windowsmap &lt;C-j&gt; &lt;C-W&gt;jmap &lt;C-k&gt; &lt;C-W&gt;kmap &lt;C-h&gt; &lt;C-W&gt;hmap &lt;C-l&gt; &lt;C-W&gt;l\" Close the current buffermap &lt;leader&gt;bd :Bclose&lt;cr&gt;\" Close all the buffersmap &lt;leader&gt;ba :1,1000 bd!&lt;cr&gt;\" Useful mappings for managing tabsmap &lt;leader&gt;tn :tabnew&lt;cr&gt;map &lt;leader&gt;to :tabonly&lt;cr&gt;map &lt;leader&gt;tc :tabclose&lt;cr&gt;map &lt;leader&gt;tm :tabmove\" Opens a new tab with the current buffer's path\" Super useful when editing files in the same directorymap &lt;leader&gt;te :tabedit &lt;c-r&gt;=expand(\"%:p:h\")&lt;cr&gt;/\" Switch CWD to the directory of the open buffermap &lt;leader&gt;cd :cd %:p:h&lt;cr&gt;:pwd&lt;cr&gt;\" Specify the behavior when switching between buffers try set switchbuf=useopen,usetab,newtab set stal=2catchendtry\" Return to last edit position when opening files (You want this!)autocmd BufReadPost * \\ if line(\"'\\\"\") &gt; 0 &amp;&amp; line(\"'\\\"\") &lt;= line(\"$\") | \\ exe \"normal! g`\\\"\" | \\ endif\" Remember info about open buffers on closeset viminfo^=%\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Status line\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Always show the status lineset laststatus=2\" Format the status lineset statusline=\\ %&#123;HasPaste()&#125;%F%m%r%h\\ %w\\ \\ CWD:\\ %r%&#123;getcwd()&#125;%h\\ \\ \\ Line:\\ %l\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Editing mappings\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Remap VIM 0 to first non-blank charactermap 0 ^\" Move a line of text using ALT+[jk] or Comamnd+[jk] on macnmap &lt;M-j&gt; mz:m+&lt;cr&gt;`znmap &lt;M-k&gt; mz:m-2&lt;cr&gt;`zvmap &lt;M-j&gt; :m'&gt;+&lt;cr&gt;`&lt;my`&gt;mzgv`yo`zvmap &lt;M-k&gt; :m'&lt;-2&lt;cr&gt;`&gt;my`&lt;mzgv`yo`zif has(\"mac\") || has(\"macunix\") nmap &lt;D-j&gt; &lt;M-j&gt; nmap &lt;D-k&gt; &lt;M-k&gt; vmap &lt;D-j&gt; &lt;M-j&gt; vmap &lt;D-k&gt; &lt;M-k&gt;endif\" Delete trailing white space on save, useful for Python and CoffeeScript ;)func! DeleteTrailingWS() exe \"normal mz\" %s/\\s\\+$//ge exe \"normal `z\"endfuncautocmd BufWrite *.py :call DeleteTrailingWS()autocmd BufWrite *.coffee :call DeleteTrailingWS()\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; vimgrep searching and cope displaying\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" When you press gv you vimgrep after the selected textvnoremap &lt;silent&gt; gv :call VisualSelection('gv')&lt;CR&gt;\" Open vimgrep and put the cursor in the right positionmap &lt;leader&gt;g :vimgrep // **/*.&lt;left&gt;&lt;left&gt;&lt;left&gt;&lt;left&gt;&lt;left&gt;&lt;left&gt;&lt;left&gt;\" Vimgreps in the current filemap &lt;leader&gt;&lt;space&gt; :vimgrep // &lt;C-R&gt;%&lt;C-A&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;&lt;right&gt;\" When you press &lt;leader&gt;r you can search and replace the selected textvnoremap &lt;silent&gt; &lt;leader&gt;r :call VisualSelection('replace')&lt;CR&gt;\" Do :help cope if you are unsure what cope is. It's super useful!\"\" When you search with vimgrep, display your results in cope by doing:\" &lt;leader&gt;cc\"\" To go to the next search result do:\" &lt;leader&gt;n\"\" To go to the previous search results do:\" &lt;leader&gt;p\"map &lt;leader&gt;cc :botright cope&lt;cr&gt;map &lt;leader&gt;co ggVGy:tabnew&lt;cr&gt;:set syntax=qf&lt;cr&gt;pggmap &lt;leader&gt;n :cn&lt;cr&gt;map &lt;leader&gt;p :cp&lt;cr&gt;\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Spell checking\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Pressing ,ss will toggle and untoggle spell checkingmap &lt;leader&gt;ss :setlocal spell!&lt;cr&gt;\" Shortcuts using &lt;leader&gt;map &lt;leader&gt;sn ]smap &lt;leader&gt;sp [smap &lt;leader&gt;sa zgmap &lt;leader&gt;s? z=\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Misc\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Remove the Windows ^M - when the encodings gets messed upnoremap &lt;Leader&gt;m mmHmt:%s/&lt;C-V&gt;&lt;cr&gt;//ge&lt;cr&gt;'tzt'm\" Quickly open a buffer for scripbblemap &lt;leader&gt;q :e ~/buffer&lt;cr&gt;\" Toggle paste mode on and offmap &lt;leader&gt;pp :setlocal paste!&lt;cr&gt;\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" =&gt; Helper functions\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"function! CmdLine(str) exe \"menu Foo.Bar :\" . a:str emenu Foo.Bar unmenu Fooendfunctionfunction! VisualSelection(direction) range let l:saved_reg = @\" execute \"normal! vgvy\" let l:pattern = escape(@\", '\\\\/.*$^~[]') let l:pattern = substitute(l:pattern, \"\\n$\", \"\", \"\") if a:direction == 'b' execute \"normal ?\" . l:pattern . \"^M\" elseif a:direction == 'gv' call CmdLine(\"vimgrep \" . '/'. l:pattern . '/' . ' **/*.') elseif a:direction == 'replace' call CmdLine(\"%s\" . '/'. l:pattern . '/') elseif a:direction == 'f' execute \"normal /\" . l:pattern . \"^M\" endif let @/ = l:pattern let @\" = l:saved_regendfunction\" Returns true if paste mode is enabledfunction! HasPaste() if &amp;paste return 'PASTE MODE ' en return ''endfunction\" Don't close window, when deleting a buffercommand! Bclose call &lt;SID&gt;BufcloseCloseIt()function! &lt;SID&gt;BufcloseCloseIt() let l:currentBufNum = bufnr(\"%\") let l:alternateBufNum = bufnr(\"#\") if buflisted(l:alternateBufNum) buffer # else bnext endif if bufnr(\"%\") == l:currentBufNum new endif if buflisted(l:currentBufNum) execute(\"bdelete! \".l:currentBufNum) endifendfunction","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yezhejack.github.io/tags/Linux/"},{"name":"vim","slug":"vim","permalink":"http://yezhejack.github.io/tags/vim/"}]},{"title":"sublime使用方法","slug":"sublime使用方法","date":"2015-11-24T02:24:12.000Z","updated":"2016-05-04T14:20:47.000Z","comments":true,"path":"2015/11/24/sublime使用方法/","link":"","permalink":"http://yezhejack.github.io/2015/11/24/sublime使用方法/","excerpt":"","keywords":null,"text":"sublime多行插入操作按住cmd然后用鼠标选择需要加入光标的位置","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"sublime","slug":"sublime","permalink":"http://yezhejack.github.io/tags/sublime/"},{"name":"编辑器","slug":"编辑器","permalink":"http://yezhejack.github.io/tags/编辑器/"}]},{"title":"Go语言的方法以及结构体  接口","slug":"Go语言的方法以及结构体","date":"2015-07-29T06:29:53.000Z","updated":"2016-05-04T14:13:53.000Z","comments":true,"path":"2015/07/29/Go语言的方法以及结构体/","link":"","permalink":"http://yezhejack.github.io/2015/07/29/Go语言的方法以及结构体/","excerpt":"","keywords":null,"text":"编译Golang Project 每次创建工程的时候都需要使用设置环境变量GOPATH来控制代码的位置1export GOPATH=&lt;path&gt; 可以设置路径 go build和go install的区别go build会生成一个输出文件，只能针对包含main函数的文件使用，会自动生成依赖go install会将二进制文件包都存在固定形式的目录下 方法 结构体的构造函数Go语言中没有构造函数这种东西，有别于C/C++。但是可以构造一个函数返回结构体指针，统一命名为New。这个称作Factory Method。 结构体的长度 1size := unsafe.Sizeof(T&#123;&#125;) 可以获得名字为T的结构体的长度 强制结构体用Factory Method来初始化将Struct Name的首字母小写，这样就导致其变为私有的（private），因此在其他包中都必须使用Factory Method来初始化结构体了 结构体的标志只能用reflect包内的内容来访问 匿名域和内嵌结构体这个和传统的OO编程中的继承很类似，可以实现一些继承的功能。直接使用类型名字来访问匿名域内嵌结构体可以直接实现继承域的功能 结构体的方法结构体的方法实际上是由函数加上一个接收者来表示这个方法是属于谁的。结构体的方法和结构体的定义都必须在同一个包里。通常接收者是一个指针 方法的继承对于多个继承关系的话，直接添加进去就好了 接口 接口定义结构1234type Namer interface &#123; Method1(param_list) return_type Method2(param_list) return_type ...&#125; 注意接口的名字是需要加上(e)r的，也就是比如一个接口的功能上我们将其命名为Select，那么接口的名字就要改为SelecterGo语言中的接口可以实例化，对应着的是一个多字的数据结构指针，未初始化时是一个nil指针 接口和实现可以放在不同的包里 利用接口实现多态将一个接口用多个结构体来实现，然后这些结构体中实现同一个接口的，然后实例化一个接口，这个接口可以用前面这些多个结构体赋值，从而实现了多态性和重载一个例子在Go的标准库io中，有定义了一个接口Reader123type Reader interface&#123; Read(p []byte)(n int, err error)&#125; 然后一下这些代码都是可行的123456var r io.Readerr=os.stdinr=bufio.NewReader(r)r = new(bytes.Buffer)f, _ := os.Open(“test.txt”)r = bufio.NewReader(f) 因为从第二行开始的右边的结构体中都实现了Reader这个接口，里面都有一个Read的函数与Reader中的对应","raw":null,"content":null,"categories":[{"name":"Programmer","slug":"Programmer","permalink":"http://yezhejack.github.io/categories/Programmer/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"http://yezhejack.github.io/tags/Golang/"},{"name":"编程语言","slug":"编程语言","permalink":"http://yezhejack.github.io/tags/编程语言/"}]},{"title":"goroutines以及channel","slug":"goroutines以及channel","date":"2015-07-28T07:20:46.000Z","updated":"2016-05-04T14:14:21.000Z","comments":true,"path":"2015/07/28/goroutines以及channel/","link":"","permalink":"http://yezhejack.github.io/2015/07/28/goroutines以及channel/","excerpt":"","keywords":null,"text":"goroutinesgoroutines并不对应着操作系统中的线程，它可以由多个线程来执行 gorouinte 之间又不像进程之间那样，使用独立的内存空间，它们使用共享的内存空间，因此它们存在读写同步的问题，使用go的channel。 gc-compiler对应着是真正的goroutines，每个都对应着一个或若干个线程，而gccgo则是为每一个goroutine建立一个线程。不要试图用print语句来显示多个进程间的真实顺序，因为print的延迟会导致显示的不是真正的顺序 channel 非缓存的channelchannel是无法暂时混存数据，因此发送端会被阻塞，除非接受端从channel中接收数据非缓存的channel很适合用于多个goroutines之间同步1234567891011package main import (“fmt” ) func f1(in chan int) &#123; fmt.Println(&lt;-in)&#125; func main() &#123; out := make(chan int) out &lt;- 2 go f1(out)&#125; 这段代码中总会出现deadlock作用。因为main这个goroutine运行到out&lt;-2时，因为是非缓存的，所以阻塞了，后面的f1还没有启动，因此所有的goroutine都进入了死亡状态 select和channel的使用 123456789 select &#123; case u:= &lt;- ch1: ... case v:= &lt;- ch2:... ... default: // no value ready to be received... &#125; 相当于是在从几个goroutine中选择已经有结果了的进行处理，如果外面加上一个无限循环的话，就能够达到不断处理的效果了针对以上这个代码如果有多个通道已经ready了的话，就随机从中选出一个如果没有ready的话它会等待如果添加了default的话，在没有一个是ready的情况下将会执行default的代码 缓存的channelcap函数可以得到buffe的大小发送端当且仅当channel满了的时候阻塞，接受端当且仅当channel空了的时候阻塞 利用goroutines和channel来进行并行编程可以讲channel当作一个信号量，用于锁住资源利用for循环的并行化 12345for i, v := range data &#123; go func (i int, v float64) &#123;&#125; doSomething(i, v)... &#125; (i, v) 利用缓存的channel来实现信号量channel的容量是我们想要进行同步的资源个数channel的现有长度是现在被占用的资源个数channel的容量－长度是现在可用的资源的个数 channel factory 模式可以在主goroutine中创建channel然后传入函数中，也可以在函数中创建channel然后返回到调用它的goroutine中来实现同步 指定channel的类型只发送或只接收 12var send_only chan&lt;- int // channel can only receive data var recv_only &lt;-chan int // channel can only send data","raw":null,"content":null,"categories":[{"name":"Programmer","slug":"Programmer","permalink":"http://yezhejack.github.io/categories/Programmer/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"http://yezhejack.github.io/tags/Golang/"},{"name":"信号量","slug":"信号量","permalink":"http://yezhejack.github.io/tags/信号量/"}]},{"title":"MAC OS X使用常见问题解决日志","slug":"MAC OS X使用常见问题解决日志","date":"2015-07-10T02:22:52.000Z","updated":"2016-05-04T14:16:12.000Z","comments":true,"path":"2015/07/10/MAC OS X使用常见问题解决日志/","link":"","permalink":"http://yezhejack.github.io/2015/07/10/MAC OS X使用常见问题解决日志/","excerpt":"","keywords":null,"text":"终端中显示的计算机名字如何更改这个的时候我也只是刚刚接触OS X刚刚几天的小白，但是作为一个认证的Unix系统，其中的终端是我肯定会用到的，但是在第一次开机配置MAC时没有注意，讲计算机的某个名称设置成了192，因此我的终端中就变成了这样12Last login: Fri Jul 10 11:04:22 on ttys000192:~ JackYip$ 每次看到这个该死的192就觉得特别的low因此萌生杀心，要解决这个问题，这里贡献一个比较快的方法，也是我使用的方法。打开终端，输入下面的命令，将其中的Tmp替换成自己想要的名字，可以支持 emoji表情的 1sudo scutil --set HostName Tmp 我就使用了Jack💪来作为HostName，这里也给出命令 1sudo scutil --set HostName Jack💪 然后用cmd＋Q强制退出终端，再开起来就可以了 常用快捷键 command+r刷新safari control+command+f 通常情况下可以最大化窗口","raw":null,"content":null,"categories":[{"name":"Howto","slug":"Howto","permalink":"http://yezhejack.github.io/categories/Howto/"}],"tags":[{"name":"MacBook Pro","slug":"MacBook-Pro","permalink":"http://yezhejack.github.io/tags/MacBook-Pro/"},{"name":"OS X","slug":"OS-X","permalink":"http://yezhejack.github.io/tags/OS-X/"}]}]}